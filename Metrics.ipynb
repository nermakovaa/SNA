{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'vk': [{'groupId': '19817989', 'posts': [{'id': 2221808, 'text': '–ê –µ—â–µ –º–Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â–µ –æ–¥–Ω—É #–í–í–Ω–æ–≤–∏–Ω–∫—É -–ü–∏—Ä–æ–∂–∫–∏ –ø–æ—Å—Ç–Ω—ã–µ —Å —Ä–∏—Å–æ–º –∏ –≥—Ä–∏–±–∞–º–∏. –ü–∏—Ä–æ–∂–∫–∏-–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–µ. –•–æ—Ä–æ—à–µ–µ —Ç–µ—Å—Ç–æ –∏ –º–Ω–æ–≥–æ –Ω–∞—á–∏–Ω–∫–∏! –ì—Ä–∏–±–æ—á–∫–∏ –≤ –Ω–∞—á–∏–Ω–∫–µ -–æ—á–µ–Ω—å –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å!', 'views': None, 'forwards': 0, 'replies': [{'text': '–ú–Ω–µ –æ–Ω–∏ —Ç–æ–∂–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å üî•', 'sender_id': 103700096, 'date': 1713129164, 'reactions': [{'emoji': 'like', 'count': 4}], 'replies': 2, 'sender_name': '–õ—é–±–æ–≤—å', 'last_name': '–ö—Ä–µ–º–∏–Ω—Å–∫–∞—è', 'sex': 1, 'city': '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥', 'bdate': '23.4'}], 'date': 1713127426, 'reactions': [{'emoji': 'like', 'count': 30}]}, {'id': 2221793, 'text': '–•–æ—Ç–µ–ª–∞ –ø–æ–¥–µ–ª–∏—Ç—å—Å—è –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ–º –æ–± üî• —ç—Ç–æ–º –ø–µ—á–µ–Ω—å–µ-#–í–í–Ω–æ–≤–∏–Ω–∫—É –ü–µ—á–µ–Ω—å–µ —Å–∞—Ö–∞—Ä–Ω–æ–µ —Å –∏–∑—é–º–æ–º. –û—á–µ–Ω—å –≤–∫—É—Å–Ω–æ–µ –ø–µ—á–µ–Ω—å–µ,–Ω–µ–∂–Ω–æ–µ –Ω–∞ –≤–∫—É—Å. –ò–∑—é–º –ø—Ä–∏–¥–∞–µ—Ç –ø–∏–∫–∞–Ω—Ç–Ω–æ—Å—Ç—å. –ü–∞—á–∫—É –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ —Å—ä–µ–ª–∏! –í—Å–µ–º —Å–æ–≤–µ—Ç—É–µ–º!', 'views': None, 'forwards': 0, 'replies': [{'text': '–ú—ã —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –±—ã—Å—Ç—Ä–æ —Å–∫—É—à–∞–ª–∏, ‚ù§ –∞ –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–π —Ä–µ—à–∏–ª–∏, —á—Ç–æ –Ω–∞–µ–ª–∏—Å—å –∏ –±–æ–ª—å—à–µ –Ω–µ —Ö–æ—Ç–∏–º üòÇ', 'sender_id': 380405, 'date': 1713132567, 'reactions': [{'emoji': 'like', 'count': 4}], 'replies': 0, 'sender_name': '–ú–∞—Ä–∏—è', 'last_name': 'Romanova', 'sex': 1, 'city': '–ú–æ—Å–∫–≤–∞', 'bdate': '17.5'}, {'text': '–ù–∞–¥–æ –±—Ä–∞—Ç—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ ‚ö°', 'sender_id': 588079193, 'date': 1713158530, 'reactions': [{'emoji': 'like', 'count': 2}], 'replies': 0, 'sender_name': '–¢–∞—Ç—å—è–Ω–∞', 'last_name': '–ë–∞–ª–∞–∫–∏—Ä–µ–≤–∞', 'sex': 1, 'city': '–ú–æ—Å–∫–≤–∞', 'bdate': '14.2.1987'}, {'text': '–£ –Ω–∞—Å —Ç–æ–∂–µ –±—ã—Å—Ç—Ä–æ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å üëé.', 'sender_id': 116534950, 'date': 1713162009, 'reactions': [{'emoji': 'like', 'count': 2}], 'replies': 0, 'sender_name': '–û–ª—å–≥–∞', 'last_name': '–ì–∞–¥–∫–æ–≤–∞-–ö–Ω—è–∑–µ–≤–∞', 'sex': 1, 'city': '–ë–∞–ª–∞—à–∏—Ö–∞', 'bdate': '6.8.1979'}, {'text': '[id150437299|–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –ë–∞–ª—É–µ–≤–∞],  üëé —Å –º–æ–ª–æ–∫–æ–º –∏–ª–∏ –∫–µ—Ñ–∏—Ä–æ–º 1% –æ–Ω–∏ –µ–¥—è—Ç—Å—è –∫–∞–∫ —Å–µ–º–µ—á–∫–∏ –°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±–∑–æ—Ä', 'sender_id': 763092240, 'date': 1713164801, 'reactions': [{'emoji': 'like', 'count': 2}], 'replies': 0, 'sender_name': '–î–µ–Ω–∏—Å', 'last_name': '–í–∫—É—Å–≤–∏–ª–ª', 'sex': 2, 'city': None, 'bdate': None}], 'date': 1713126995, 'reactions': [{'emoji': 'like', 'count': 26}]}, {'id': 2220000, 'text': '–ü—Ä–µ–∫—Ä–∞—Å–Ω–∞—è –ø—è—Ç–Ω–∏—Ü–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç –∫ —Å–≤–æ–µ–º—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é. –ù–∞–¥–µ–µ–º—Å—è, —á—Ç–æ –≤–∫—É—Å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Å–º–æ–≥–ª–∏ —Å–µ–≥–æ–¥–Ω—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤–∞—Å –≤ –ø–æ–ª–µ—Ç –Ω–∞—Å–ª–∞–∂–¥–µ–Ω–∏–π‚ù§. –í—ã —É–∂–µ —É—Å–ø–µ–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞—à—É —Ä–∞–∫–µ—Ç—É? –ï—Å–ª–∏ –µ—â—ë –Ω–µ—Ç, —Ç–æ –Ω–∞–π—Ç–∏ –µ—ë –º–æ–∂–µ—Ç–µ', 'views': 120, 'forwards': 0, 'replies': [{'text': '–ü–æ–π–¥—É –∑–∞–ø—É—Å–∫–∞—Ç—å —Ä–∞–∫–µ—Ç—É –≤—Å–µ–º —Ö–æ—Ä–æ—à–µ–≥–æ –≤–µ—á–µ—Ä–∞ –∏ –¥–æ –Ω–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á', 'sender_id': 588079193, 'date': 1712945765, 'reactions': [{'emoji': 'like', 'count': 7}], 'replies': 0, 'sender_name': '–¢–∞—Ç—å—è–Ω–∞', 'last_name': '–ë–∞–ª–∞–∫–∏—Ä–µ–≤–∞', 'sex': 1, 'city': '–ú–æ—Å–∫–≤–∞', 'bdate': '14.2.1987'}, {'text': '–°–∫–∞–∑–æ—á–Ω–æ–µ —Ñ–æ—Ç–æ, —Å–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏', 'sender_id': 66139334, 'date': 1712947002, 'reactions': [{'emoji': 'like', 'count': 7}], 'replies': 0, 'sender_name': '–ù–∞—Ç–∞–ª—å—è', 'last_name': '–ö–æ—Å—Ç–æ–º–∞—Ö–∏–Ω–∞', 'sex': 1, 'city': '–ú–æ—Å–∫–≤–∞', 'bdate': None}, {'text': '–í–∞–∞–∞–∞—É, —Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–∞–∫–æ–µ —Ñ–æ—Ç–æ, –î–µ–Ω–∏—Å!! –ò –≤–∞–º –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–≥–æ –≤–µ—á–µ—Ä–∞! üòç', 'sender_id': 15449237, 'date': 1712947114, 'reactions': [{'emoji': 'like', 'count': 7}], 'replies': 0, 'sender_name': '–û–ª—å–≥–∞', 'last_name': '–ì–ª—É—à–∞–∫–æ–≤–∞', 'sex': 1, 'city': '–°–µ—Ä—Ç–æ–ª–æ–≤–æ', 'bdate': '5.4.1988'}], 'date': 1712614133, 'reactions': [{'emoji': 'like', 'count': 42}]}], 'membersCount': 77335, 'membersIds': [108718, 109631, 110048, 110286, 110351, 110393, 110690, 110829, 110971, 111011, 111576, 111683, 112011, 112592, 112734, 114255, 114762, 114799, 115474, 116330, 116581, 116909, 116985, 117270, 117709, 118719, 118740, 119392, 119509, 119898, 120069, 120900, 120934, 121094, 121248, 121507, 121837, 122262, 123806, 124398, 124819, 125473, 126453, 126461, 127323, 127350, 127781, 128303, 128542, 129867, 129880, 130294, 130357, 130986, 131182, 131189, 131508, 131608, 131875, 132357, 132540, 132658, 132785, 133412, 133580, 133718, 133818, 134281, 134553, 134578, 134854, 134935, 136050, 136144, 136363, 137257, 137892, 138310, 138748, 139089, 139367, 139437, 139767, 139777, 139780, 140086, 140146, 140874, 140882, 141391, 141684, 142758, 143014, 143080, 143201, 143313, 143478, 144185, 144486, 144671, 145139, 145908, 145987, 146277, 147188, 147772, 147871, 148720, 149135, 151314, 151710, 151833, 152687, 152702, 153045, 153581, 153633, 153678, 154463, 155061, 157312, 158621, 158813, 159173, 159278, 159325, 159439, 159620, 160280, 160432, 160969, 161234, 161284, 161380, 162198, 162607, 163928, 164345, 164888, 165026, 166163, 166616, 166884, 167574, 167788, 168231, 168264, 169000, 169294, 169594, 170530, 170795, 171250, 172410, 173538, 173621, 174034, 174053, 174688, 175731, 175803, 176785, 176983, 177453, 177527, 177737, 177842, 177855, 177997, 178233, 178404, 179255, 179380, 180648, 180674, 181413, 181438, 182322, 182600, 183499, 183555, 183728, 183905, 184245, 185685, 186025, 186072, 186202, 186614, 186908, 187136, 188644, 188748, 188947, 189302, 189424, 190135, 190284, 190468, 190605, 191431, 191690, 191897, 192970, 193044, 193375, 194640, 195347, 195488, 195703, 195730, 195911, 196433, 196896, 197504, 197582, 198443, 199383, 199443, 200414, 200558, 201123, 202616, 203461, 203793, 203955, 204175, 204240, 205365, 205602, 206226, 207052, 207426, 207799, 207911, 208005, 208486, 208736, 209130, 209139, 209729, 210340, 211118, 211846, 211948, 212283, 212490, 212862, 214147, 214178, 214295, 214989, 215370, 215549, 216020, 216944, 217212, 217280, 217809, 217896, 219054, 219060, 219617, 219934, 221169, 221287, 221356, 221603, 221951, 222161, 222216, 222488, 223833, 224065, 224356, 224774, 224911, 225031, 225124, 225403, 225590, 225884, 226394, 227107, 227114, 227907, 228007, 228326, 228494, 228515, 229228, 229320, 229524, 229813, 230101, 230323, 230587, 230634, 231777, 232112, 232354, 232398, 232737, 233190, 233261, 233670, 233679, 233921, 234123, 235233, 237863, 239171, 239471, 239480, 239939, 240162, 240207, 240318, 241143, 241364, 241535, 241552, 241631, 242060, 242852, 243169, 243643, 243892, 244693, 244850, 244861, 244878, 244923, 245546, 246345, 247367, 247648, 247912, 248137, 248221, 248317, 248468, 248527, 248677, 248867, 249509, 249833, 250230, 250873, 250939, 251228, 251481, 251757, 252069, 253684, 254151, 254320, 254421, 255038, 255174, 256254, 256312, 256684, 256758, 256796, 257497, 257757, 258201, 258624, 258784, 258864, 259078, 259415, 259718, 260011, 261094, 261685, 261816, 261848, 261872, 262129, 262153, 262960, 263277, 264414, 264571, 264950, 265213, 265299, 265354, 265467, 266695, 266775, 267008, 267353, 267782, 268082, 268563, 268755, 268953, 269105, 269162, 269335, 269359, 269612, 269767, 270015, 270036, 270205, 270507, 270718, 271382, 271730, 271778, 272102, 272103, 272856, 273365, 273557, 273727, 274057, 274443, 274640, 274798, 275058, 275524, 275576, 276253, 276412, 276700, 276834, 277310, 277618, 277875, 278116, 278551, 279231, 279356, 279609, 279736, 280045, 280580, 281677, 281690, 282428, 282503, 282891, 282963, 283108, 283663, 283916, 284234, 284440, 285044, 285413, 285606, 285681, 286015, 286196, 286723, 286745, 286873, 287349, 287566, 287652, 287678, 288326, 288398, 288654, 289968, 290044, 290334, 290559, 290622, 290922, 291105, 291107, 291174, 291735, 291940, 292562, 292842, 293246, 293364, 293370, 293694, 295110, 295141, 295462, 296002, 296459, 296645, 297748, 297783, 298394, 298912, 298977, 299267, 299970, 300129], 'crawlingTitle': '–Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π [vk]', 'from': '9/4/2024', 'to': '14/4/2024', 'groupName': '–í–∫—É—Å–í–∏–ª–ª. –ó–¥–µ—Å—å –ø–æ–ª–µ–∑–Ω–æ–µ –≤–∫—É—Å–Ω–æ'}], 'tg': [{'chatId': 'we_are_vkusvill', 'posts': [{'id': 5411, 'text': '–ê –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —É–∑–Ω–∞—Ç—å, —á—Ç–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –µ–¥—è—Ç –≤ –∫–æ—Å–º–æ—Å–µ ‚Äî –∏', 'replies': [{'sender_id': 503928602, 'sender_name': 'Lilamam', 'last_name': None, 'sex': None, 'city': None, 'bdate': None, 'text': '–ê –ø–æ—á–µ–º—É —É –≤–∞—Å –Ω–µ—Ç –≤–æ–¥—ã –ª–µ–≥–µ–Ω–¥–∞ –≥–æ—Ä –≤ 19 –ª–∏—Ç—Ä–æ–≤—ã—Ö –±—É—Ç—ã–ª–∫–∞—Ö?))', 'date': '04/13/2024', 'reactions': [{'emoji': 'ü•∞', 'count': 1}], 'replies': None}, {'sender_id': 875429873, 'sender_name': '–ï–ª–µ–Ω–∞', 'last_name': None, 'sex': None, 'city': None, 'bdate': None, 'text': '–ë–µ–Ω—Ç–æ —Å–æ —Å–≥—É—â–µ–Ω–∫–æ–π', 'date': '04/13/2024', 'reactions': [{'emoji': 'üòÅ', 'count': 1}], 'replies': None}, {'sender_id': 432568275, 'sender_name': 'One', 'last_name': 'One', 'sex': None, 'city': None, 'bdate': None, 'text': '–û, —Å–ª–æ–≤–µ—á–∫–∏ –≤–µ—Ä–Ω—É–ª–∏—Å—å', 'date': '04/12/2024', 'reactions': [{'emoji': '‚ù§', 'count': 5}], 'replies': None}], 'views': 23489, 'forwards': 20, 'post_date': '04/12/2024', 'reactions': [{'emoji': '‚ù§', 'count': 118}, {'emoji': 'üî•', 'count': 55}, {'emoji': None, 'count': 27}, {'emoji': 'üòç', 'count': 8}, {'emoji': 'üíØ', 'count': 5}, {'emoji': 'üëç', 'count': 3}, {'emoji': '‚ö°', 'count': 3}, {'emoji': 'üëé', 'count': 1}]}, {'id': 5401, 'text': '–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –º–æ–∂–µ—Ç–µ –∑–∞–ø—Ä—ã–≥–Ω—É—Ç—å –≤ –∫–æ—Å–º–∏—á–µ—Å–∫–∏–π –∫–æ—Ä–∞–±–ª—å, –ø—Ä–æ–Ω–∑–∏—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏ –æ–∫–∞–∑–∞—Ç—å—Å—è –Ω–∞ –æ–¥–Ω–æ–π –∏–∑ –ø–ª–∞–Ω–µ—Ç –≥–¥–µ-—Ç–æ –≤–æ –í–∫—É—Å–Ω–æ–π...', 'replies': [{'sender_id': -1001403138288, 'sender_name': '–í–∫—É—Å–í–∏–ª–ª –∫–æ–º–º.', 'last_name': 'Admin', 'sex': None, 'city': None, 'bdate': None, 'text': '–î–æ–±—Ä—ã–π –¥–µ–Ω—å, –ê–ª–∏–Ω–∞', 'date': '04/13/2024', 'reactions': [{'emoji': '‚ù§', 'count': 1}], 'replies': None}, {'sender_id': -1001403138288, 'sender_name': '–í–∫—É—Å–í–∏–ª–ª –∫–æ–º–º.', 'last_name': 'Admin', 'sex': None, 'city': None, 'bdate': None, 'text': None, 'date': '04/13/2024', 'reactions': [{'emoji': '‚ö°', 'count': 1}], 'replies': None}, {'sender_id': -1001403138288, 'sender_name': '–í–∫—É—Å–í–∏–ª–ª –∫–æ–º–º.', 'last_name': 'Admin', 'sex': None, 'city': None, 'bdate': None, 'text': '–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –≤–∞—Å –≤ —ç—Ç–æ–º –≤—ã–±–æ—Ä–µ', 'date': '04/12/2024', 'reactions': [{'emoji': '‚ù§', 'count': 1}], 'replies': None}, {'sender_id': 453818767, 'sender_name': '–°–µ—Ä–≥–µ–π', 'last_name': '–î–æ–ª–≥–æ–≤ ', 'sex': None, 'city': None, 'bdate': None, 'text': '–Ø –Ω–∞ —Ö–ª–µ–±–Ω–æ–π –ø–ª–∞–Ω–µ—Ç–µ —É–∂–µ 7 –ª–µ—Ç)', 'date': '04/12/2024', 'reactions': [{'emoji': '‚ù§', 'count': 1}], 'replies': None}, {'sender_id': -1001403138288, 'sender_name': '–í–∫—É—Å–í–∏–ª–ª –∫–æ–º–º.', 'last_name': 'Admin', 'sex': None, 'city': None, 'bdate': None, 'text': '–õ—é–±–∏–º–æ–µ –º–æ—Ä–æ–∂–µ–Ω–æ–µ. –ò –Ω–∞ –ü–ª–æ–º–±–∏—Ä–Ω–æ–π –ø–ª–∞–Ω–µ—Ç–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø–æ–ø–æ–ª–Ω—è—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –≤–µ–¥–µ—Ä–∫–æ', 'date': '04/12/2024', 'reactions': [{'emoji': 'üëç', 'count': 4}, {'emoji': '‚ù§', 'count': 2}], 'replies': None}, {'sender_id': 222641683, 'sender_name': 'Mii', 'last_name': None, 'sex': None, 'city': None, 'bdate': None, 'text': '–ü—Ä–æ–º–æ–∫–æ–¥–æ–≤ –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–∞–≤–Ω–æ –Ω–µ –±—ã–ª–æ(', 'date': '04/09/2024', 'reactions': [{'emoji': '‚ù§', 'count': 17}], 'replies': None}], 'views': 29822, 'forwards': 117, 'post_date': '04/09/2024', 'reactions': [{'emoji': '‚ù§', 'count': 470}, {'emoji': 'üëç', 'count': 79}, {'emoji': 'ü§£', 'count': 71}, {'emoji': None, 'count': 64}, {'emoji': 'üëé', 'count': 35}, {'emoji': '‚ö°', 'count': 22}, {'emoji': 'üî•', 'count': 19}]}], 'membersCount': 116660, 'membersIds': [], 'crawlingTitle': '–Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π [tg]', 'from': '9/4/2024', 'to': '14/4/2024', 'chatTitle': '–í–∫—É—Å–í–∏–ª–ª'}]}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open('/home/nermakovaa/semester_4/SNA/SNA/data/data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Love Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1029618652810864"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def love_rate(data):\n",
    "    \"\"\"\n",
    "    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (Love Rate)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤ / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ ) * 100%\n",
    "    \"\"\"\n",
    "    total_views = 0\n",
    "    total_likes = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            total_views += sum([0 if _[\"views\"] is None else _[\"views\"] for _ in item[\"posts\"]])\n",
    "            total_likes += sum([reaction[\"count\"] for post in item[\"posts\"] for reaction in post[\"reactions\"] if reaction[\"emoji\"] == \"‚ù§\"])\n",
    "\n",
    "    if total_views > 0 and total_likes > 0:\n",
    "        love_rate = (total_likes / total_views) * 100\n",
    "        return love_rate\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "love_rate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9626264357963312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engagement_rate(data):\n",
    "    '''\n",
    "    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (Engagement Rate)\n",
    "    (–û–±—â–µ–µ —á–∏—Å–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π / –û–±—â–µ–µ —á–∏—Å–ª–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤) * 100%\n",
    "    '''\n",
    "    total_interactions = 0\n",
    "    total_comments = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            followers = item['membersCount']\n",
    "            likes = sum(reaction['count'] for post in item['posts'] for reaction in post['reactions'])\n",
    "            reposts = sum(post['forwards'] for post in item['posts'])\n",
    "\n",
    "            unique_sender_ids = set(comment['sender_id'] for post in item['posts'] for comment in post.get('replies', []))\n",
    "\n",
    "            total_comments += len(unique_sender_ids)\n",
    "            total_interactions += likes + total_comments + reposts\n",
    "\n",
    "    if total_interactions > 0 and followers > 0:\n",
    "        engagement_rate = (total_interactions / followers) * 100\n",
    "        return engagement_rate\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "engagement_rate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Rate By Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.106507099848061"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engagement_rate_by_reach(data):\n",
    "    '''\n",
    "    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (Engagement Rate By Reach)\n",
    "    (–û–±—â–µ–µ —á–∏—Å–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤) * 100%\n",
    "    '''\n",
    "    total_interactions = 0\n",
    "    total_comments = 0\n",
    "    total_views = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            total_views += sum([0 if _[\"views\"] is None else _[\"views\"] for _ in item[\"posts\"]])\n",
    "            \n",
    "            likes = sum(reaction['count'] for post in item['posts'] for reaction in post['reactions'])\n",
    "            reposts = sum(post.get('forwards', 0) for post in item['posts'])  \n",
    "\n",
    "            unique_sender_ids = set(comment['sender_id'] for post in item['posts'] for comment in post.get('replies', []))\n",
    "\n",
    "            total_comments += len(unique_sender_ids)\n",
    "            total_interactions += likes + total_comments + reposts\n",
    "\n",
    "    if total_interactions > 0 and total_views > 0:\n",
    "        engagement_rate_by_reach = (total_interactions / total_views) * 100\n",
    "        return engagement_rate_by_reach\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "engagement_rate_by_reach(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –∞—É–¥–∏—Ç–æ—Ä–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23332"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def audience_coverage(data):\n",
    "    '''\n",
    "    –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –∞—É–¥–∏—Ç–æ—Ä–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞ (Audience Coverage)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤/–ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤/—Ä–µ–ø–æ—Å—Ç–æ–≤/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π) / (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞) \n",
    "    '''\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            total_interactions = item[\"membersCount\"]\n",
    "            \n",
    "            start_date = datetime.strptime(item[\"from\"], \"%d/%m/%Y\")\n",
    "            end_date = datetime.strptime(item[\"to\"], \"%d/%m/%Y\")\n",
    "            days_between = (end_date - start_date).days\n",
    "                \n",
    "    if total_interactions > 0 and days_between > 0:\n",
    "        audience_coverage = (total_interactions / days_between) \n",
    "        return int(audience_coverage)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "audience_coverage(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Citation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25698261146855245"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def channel_citation_index(data):\n",
    "    \"\"\"\n",
    "    –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ (Channel Citation Index)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ—Å—Ç–æ–≤ / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤) * 100%\n",
    "    \"\"\"\n",
    "    total_views = 0\n",
    "    total_reposts = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            valid_posts = [post for post in item[\"posts\"] if post[\"views\"] is not None] \n",
    "            total_views += sum([post[\"views\"] for post in valid_posts])\n",
    "            total_reposts = sum(post.get('forwards', 0) for post in item['posts'])  \n",
    "\n",
    "    if total_views > 0 and total_reposts > 0:\n",
    "        channel_citation_index = (total_reposts / total_views) * 100\n",
    "        return channel_citation_index\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "channel_citation_index(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discussion_rate(data):\n",
    "    \"\"\"\n",
    "    –û–±—Å—É–∂–¥–∞–µ–º–æ—Å—Ç—å –ø–æ—Å—Ç–æ–≤ (Discussion Rate)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤) / (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –ø–æ–¥–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö) * 100% \n",
    "    \"\"\"\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            comment = [comment['sender_id'] for post in item['posts'] for comment in post.get('replies', [])]\n",
    "            \n",
    "            total_comment = len(comment)\n",
    "            unique_sender_ids = len(set(comment))\n",
    "            \n",
    "    if unique_sender_ids == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        discussion_rate = (total_comment / unique_sender_ids) * 100\n",
    "        return discussion_rate\n",
    "            \n",
    "\n",
    "discussion_rate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Analysis for messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"null\": {\n",
      "        \"users_count\": 9,\n",
      "        \"percent\": 100.0,\n",
      "        \"user_messages\": [\n",
      "            \"–ê –ø–æ—á–µ–º—É —É –≤–∞—Å –Ω–µ—Ç –≤–æ–¥—ã –ª–µ–≥–µ–Ω–¥–∞ –≥–æ—Ä –≤ 19 –ª–∏—Ç—Ä–æ–≤—ã—Ö –±—É—Ç—ã–ª–∫–∞—Ö?))\",\n",
      "            \"–ë–µ–Ω—Ç–æ —Å–æ —Å–≥—É—â–µ–Ω–∫–æ–π\",\n",
      "            \"–û, —Å–ª–æ–≤–µ—á–∫–∏ –≤–µ—Ä–Ω—É–ª–∏—Å—å\",\n",
      "            \"–î–æ–±—Ä—ã–π –¥–µ–Ω—å, –ê–ª–∏–Ω–∞\",\n",
      "            \"–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –≤–∞—Å –≤ —ç—Ç–æ–º –≤—ã–±–æ—Ä–µ\",\n",
      "            \"–Ø –Ω–∞ —Ö–ª–µ–±–Ω–æ–π –ø–ª–∞–Ω–µ—Ç–µ —É–∂–µ 7 –ª–µ—Ç)\",\n",
      "            \"–õ—é–±–∏–º–æ–µ –º–æ—Ä–æ–∂–µ–Ω–æ–µ. –ò –Ω–∞ –ü–ª–æ–º–±–∏—Ä–Ω–æ–π –ø–ª–∞–Ω–µ—Ç–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø–æ–ø–æ–ª–Ω—è—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –≤–µ–¥–µ—Ä–∫–æ\",\n",
      "            \"–ü—Ä–æ–º–æ–∫–æ–¥–æ–≤ –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–∞–≤–Ω–æ –Ω–µ –±—ã–ª–æ(\"\n",
      "        ],\n",
      "        \"positive\": 0.125,\n",
      "        \"negative\": 0.125,\n",
      "        \"neutral\": 0.75\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def top_regions(data):\n",
    "    '''\n",
    "    –¢–æ–ø-20 —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    [—Ä–µ–≥–∏–æ–Ω | –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π | % | —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å]\n",
    "    '''\n",
    "    # https://huggingface.co/blanchefort/rubert-base-cased-sentiment –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "\n",
    "    city_users = {}\n",
    "\n",
    "    total_users = 0\n",
    "    \n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            for post in item['posts']:\n",
    "                for reply in post.get('replies', []):\n",
    "                    city = reply.get('city', 'Unknown')\n",
    "                    if city not in city_users:\n",
    "                        city_users[city] = []\n",
    "                    city_users[city].append(reply['sender_id'])\n",
    "                    total_users += 1\n",
    "\n",
    "    city_stats = {}\n",
    "    for city, users in city_users.items():\n",
    "        users_count = len(users)\n",
    "        percent = (users_count / total_users) * 100\n",
    "\n",
    "        user_messages = [post['text'] for post in item['posts'] for post in post['replies'] if post.get('city') == city and post['text'] is not None]\n",
    "        classified_messages = classifier(user_messages)\n",
    "        len_messages = len(classified_messages)\n",
    "        positive = len([i for i in classified_messages if i['label']=='POSITIVE']) / len_messages\n",
    "        negative = len([i for i in classified_messages if i['label']=='NEGATIVE']) / len_messages\n",
    "        neutral = len([i for i in classified_messages if i['label']=='NEUTRAL']) / len_messages\n",
    "\n",
    "        city_stats[city] = {\n",
    "            'users_count': users_count,\n",
    "            'percent': percent,\n",
    "            'user_messages': user_messages,\n",
    "            'positive': positive,\n",
    "            'negative': negative,\n",
    "            'neutral': neutral\n",
    "        }\n",
    "\n",
    "    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ø-20, —Å–æ—Ä—Ç–∏—Ä—É–µ–º city_stats –ø–æ users_count \n",
    "    sorted_city_stats = dict(sorted(city_stats.items(), key=lambda x: x[1]['users_count'], reverse=True)[:20])\n",
    "\n",
    "    top_regions = json.dumps(sorted_city_stats, indent=4, ensure_ascii=False)\n",
    "    return top_regions\n",
    "\n",
    "\n",
    "result = top_regions(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Promoter Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–ê –ø–æ—á–µ–º—É —É –≤–∞—Å –Ω–µ—Ç –≤–æ–¥—ã –ª–µ–≥–µ–Ω–¥–∞ –≥–æ—Ä –≤ 19 –ª–∏—Ç—Ä–æ–≤—ã—Ö –±—É—Ç—ã–ª–∫–∞—Ö?))', '–ë–µ–Ω—Ç–æ —Å–æ —Å–≥—É—â–µ–Ω–∫–æ–π', '–û, —Å–ª–æ–≤–µ—á–∫–∏ –≤–µ—Ä–Ω—É–ª–∏—Å—å', '–î–æ–±—Ä—ã–π –¥–µ–Ω—å, –ê–ª–∏–Ω–∞', '–ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –≤–∞—Å –≤ —ç—Ç–æ–º –≤—ã–±–æ—Ä–µ', '–Ø –Ω–∞ —Ö–ª–µ–±–Ω–æ–π –ø–ª–∞–Ω–µ—Ç–µ —É–∂–µ 7 –ª–µ—Ç)', '–õ—é–±–∏–º–æ–µ –º–æ—Ä–æ–∂–µ–Ω–æ–µ. –ò –Ω–∞ –ü–ª–æ–º–±–∏—Ä–Ω–æ–π –ø–ª–∞–Ω–µ—Ç–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø–æ–ø–æ–ª–Ω—è—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ –≤–µ–¥–µ—Ä–∫–æ', '–ü—Ä–æ–º–æ–∫–æ–¥–æ–≤ –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–∞–≤–Ω–æ –Ω–µ –±—ã–ª–æ(']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def net_promoter_score(data):\n",
    "    \"\"\"\n",
    "    –õ–æ—è–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (Net Promoter Score)\n",
    "    ((–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ - –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏) / –í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤) * 100%\n",
    "    \"\"\"\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "\n",
    "    for i in data:\n",
    "        for item in i['tg']:\n",
    "            total_messages = [post['text'] for post in item['posts'] for post in post['replies'] if post['text'] is not None]\n",
    "            print(total_messages)\n",
    "            len_total_messages = len(total_messages)\n",
    "            \n",
    "            classified_messages = classifier(total_messages)\n",
    "            positive_count = sum(1 for i in classified_messages if i['label'] == 'POSITIVE')\n",
    "            negative_count = sum(1 for i in classified_messages if i['label'] == 'NEGATIVE')\n",
    "\n",
    "    if len_total_messages > 0:\n",
    "        net_promoter_score = ((positive_count - negative_count) / len_total_messages) * 100\n",
    "        return net_promoter_score\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "net_promoter_score(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ –¥–ª–∏–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0-10': {'positive': 0, 'negative': 0, 'neutral': 0},\n",
       " '11-50': {'positive': 0,\n",
       "  'negative': 19.524068842154584,\n",
       "  'neutral': 80.47593115784542},\n",
       " '51-100': {'positive': 54.90797873326216,\n",
       "  'negative': 0,\n",
       "  'neutral': 45.092021266737845},\n",
       " '101-200': {'positive': 0, 'negative': 0, 'neutral': 0},\n",
       " '201+': {'positive': 0, 'negative': 0, 'neutral': 0}}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def character_length(data):\n",
    "    '''\n",
    "    –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ –¥–ª–∏–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ | —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å]\n",
    "    '''\n",
    "    lists = []\n",
    "    results = []\n",
    "    \n",
    "    # https://huggingface.co/blanchefort/rubert-base-cased-sentiment –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "    \n",
    "    # –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª–∏–Ω —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    dict_lengths = {1: '0-10', 2: '11-50', 3: '51-100', 4: '101-200', 5: '201+'}\n",
    "\n",
    "    comments_lengths = {\n",
    "        dict_lengths[1]: [],\n",
    "        dict_lengths[2]: [],\n",
    "        dict_lengths[3]: [],\n",
    "        dict_lengths[4]: [],\n",
    "        dict_lengths[5]: [] \n",
    "    }\n",
    "\n",
    "    for group in data:\n",
    "        for post in group['tg'][0]['posts']:\n",
    "            for reply in post['replies']:\n",
    "                if reply['text'] != None:\n",
    "                    comment_length = len(reply['text'])\n",
    "                    if comment_length < int(dict_lengths[1].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[1]].append(reply['text'])\n",
    "                    elif int(dict_lengths[1].split('-')[1])+1 <= comment_length <= int(dict_lengths[2].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[2]].append(reply['text'])\n",
    "                    elif int(dict_lengths[2].split('-')[1])+1 <= comment_length <= int(dict_lengths[3].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[3]].append(reply['text'])\n",
    "                    elif int(dict_lengths[3].split('-')[1])+1 <= comment_length <= int(dict_lengths[4].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[4]].append(reply['text'])\n",
    "                    else:\n",
    "                        comments_lengths[dict_lengths[5]].append(reply['text'])\n",
    "\n",
    "    for lengths in comments_lengths.keys():\n",
    "        lists.append([classifier(_) for _ in comments_lengths[lengths]])\n",
    "        \n",
    "    length_keys = dict_lengths.values()\n",
    "\n",
    "    for list in lists:\n",
    "        total_score = sum(dict['score'] for sublist in list for dict in sublist)\n",
    "\n",
    "        distribution = {'positive': 0, 'negative': 0, 'neutral': 0} \n",
    "        if total_score != 0:\n",
    "            for sublist in list:\n",
    "                for dict in sublist:\n",
    "                    distribution[dict['label'].lower()] += (dict['score'] / total_score) * 100\n",
    "\n",
    "        results.append(distribution)\n",
    "\n",
    "    comments_lengths_sentimentary = {}\n",
    "    for i, dist in zip(length_keys, results):\n",
    "        comments_lengths_sentimentary[i] = dist\n",
    "\n",
    "    return comments_lengths_sentimentary\n",
    "\n",
    "\n",
    "character_length(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–ø —ç–º–æ–¥–∑–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'‚ù§': 588, 'üëç': 82, 'üî•': 74, 'ü§£': 71, 'üëé': 36}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_emoji(data):\n",
    "    '''\n",
    "    –¢–æ–ø-5 —ç–º–æ–¥–∑–∏\n",
    "    [—ç–º–æ–¥–∑–∏ | –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —ç–º–æ–¥–∑–∏]\n",
    "    '''\n",
    "    reactions_summary = {}\n",
    "    \n",
    "    for group in data:\n",
    "        posts = (post_item for item in group['tg'] for post_item in item['posts'])\n",
    "        \n",
    "        for post_item in posts:\n",
    "            reactions = post_item.get('reactions', {})\n",
    "            \n",
    "            if reactions is not None:\n",
    "                for reaction in filter(lambda r: r['emoji'] is not None, reactions):\n",
    "                    emoji = reaction['emoji']\n",
    "                    count = reaction['count']\n",
    "                    \n",
    "                    reactions_summary[emoji] = reactions_summary.get(emoji, 0) + count\n",
    "\n",
    "    top_reactions = dict(sorted(reactions_summary.items(), key=lambda x: x[1], reverse=True)[:5])\n",
    "    return top_reactions  \n",
    "    \n",
    "    \n",
    "top_emoji(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í–ö–æ–Ω—Ç–∞–∫—Ç–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Love Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def love_rate(data):\n",
    "    \"\"\"\n",
    "    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (Love Rate)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤ / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤) * 100%\n",
    "    \"\"\"\n",
    "    total_views = 0\n",
    "    total_likes = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            valid_posts = [post for post in item[\"posts\"] if post[\"views\"] is not None] # —Ç–æ–ª—å–∫–æ —Ç–µ –ø–æ—Å—Ç—ã, –≥–¥–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã != None\n",
    "            total_views += sum([post[\"views\"] for post in valid_posts])\n",
    "            total_likes += sum([reaction[\"count\"] for post in valid_posts for reaction in post[\"reactions\"] if reaction[\"emoji\"] == \"like\"])\n",
    "\n",
    "    if total_views > 0 and total_likes > 0:\n",
    "        love_rate = (total_likes / total_views) * 100\n",
    "        return love_rate\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "love_rate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.135772935928105"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engagement_rate(data):\n",
    "    '''\n",
    "    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (Engagement Rate)\n",
    "    (–û–±—â–µ–µ —á–∏—Å–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π / –û–±—â–µ–µ —á–∏—Å–ª–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤) * 100%\n",
    "    '''\n",
    "    total_interactions = 0\n",
    "    total_comments = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            followers = item['membersCount']\n",
    "            likes = sum(reaction['count'] for post in item['posts'] for reaction in post['reactions'])\n",
    "            reposts = sum(post['forwards'] for post in item['posts'])\n",
    "\n",
    "            unique_sender_ids = set(comment['sender_id'] for post in item['posts'] for comment in post.get('replies', []))\n",
    "\n",
    "            total_comments += len(unique_sender_ids)\n",
    "            total_interactions += likes + total_comments + reposts\n",
    "\n",
    "    if total_interactions > 0 and followers > 0:\n",
    "        engagement_rate = (total_interactions / followers) * 100\n",
    "        return engagement_rate\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "engagement_rate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engagement Rate By Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def engagement_rate_by_reach(data):\n",
    "    '''\n",
    "    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (Engagement Rate By Reach)\n",
    "    (–û–±—â–µ–µ —á–∏—Å–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤) * 100%\n",
    "    '''\n",
    "    total_interactions = 0\n",
    "    total_comments = 0\n",
    "    total_views = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            valid_posts = [post for post in item[\"posts\"] if post[\"views\"] is not None] \n",
    "            total_views += sum([post[\"views\"] for post in valid_posts])\n",
    "            \n",
    "            likes = sum(reaction['count'] for post in item['posts'] for reaction in post['reactions'])\n",
    "            reposts = sum(post.get('forwards', 0) for post in item['posts'])  \n",
    "\n",
    "            unique_sender_ids = set(comment['sender_id'] for post in item['posts'] for comment in post.get('replies', []))\n",
    "\n",
    "            total_comments += len(unique_sender_ids)\n",
    "            total_interactions += likes + total_comments + reposts\n",
    "\n",
    "    if total_interactions > 0 and total_views > 0:\n",
    "        engagement_rate_by_reach = (total_interactions / total_views) * 100\n",
    "        return engagement_rate_by_reach\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "engagement_rate_by_reach(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –∞—É–¥–∏—Ç–æ—Ä–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def audience_coverage(data):\n",
    "    '''\n",
    "    –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –∞—É–¥–∏—Ç–æ—Ä–Ω–æ–≥–æ –æ—Ö–≤–∞—Ç–∞ (Audience Coverage)\n",
    "    (–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤ + –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ + –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ—Å—Ç–æ–≤ + –∫–æ–ª–∏—á–µ—Å—Ç–∫–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ + \n",
    "    –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞–π–∫–æ–≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤)) / (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞) \n",
    "    '''\n",
    "    total_interactions = 0\n",
    "    total_comments = 0\n",
    "    total_views = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            valid_posts = [post for post in item[\"posts\"] if post[\"views\"] is not None] \n",
    "            total_views += sum([post[\"views\"] for post in valid_posts])\n",
    "            \n",
    "            likes_comments = sum([reaction['count'] for post in item['posts'] for comment in post.get('replies', []) for reaction in comment.get('reactions', [])])\n",
    "            total_likes = sum(reaction['count'] for post in item['posts'] for reaction in post['reactions']) + likes_comments\n",
    "            \n",
    "            reposts = sum(post.get('forwards', 0) for post in item['posts'])  \n",
    "\n",
    "            unique_sender_ids = set(comment['sender_id'] for post in item['posts'] for comment in post.get('replies', []))\n",
    "\n",
    "            total_comments += len(unique_sender_ids)\n",
    "            total_interactions += total_likes + total_comments + reposts + total_views\n",
    "            \n",
    "            start_date = datetime.strptime(item[\"from\"], \"%d/%m/%Y\")\n",
    "            end_date = datetime.strptime(item[\"to\"], \"%d/%m/%Y\")\n",
    "            days_between = (end_date - start_date).days\n",
    "                \n",
    "    if total_interactions > 0 and days_between > 0:\n",
    "        audience_coverage = (total_interactions / days_between) \n",
    "        return int(audience_coverage)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "audience_coverage(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Citation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def channel_citation_index(data):\n",
    "    \"\"\"\n",
    "    –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏ (Channel Citation Index)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–æ—Å—Ç–æ–≤ / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤) * 100%\n",
    "    \"\"\"\n",
    "    total_views = 0\n",
    "    total_reposts = 0\n",
    "\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            valid_posts = [post for post in item[\"posts\"] if post[\"views\"] is not None] \n",
    "            total_views += sum([post[\"views\"] for post in valid_posts])\n",
    "            total_reposts = sum(post.get('forwards', 0) for post in item['posts'])  \n",
    "\n",
    "    if total_views > 0 and total_reposts > 0:\n",
    "        channel_citation_index = (total_reposts / total_views) * 100\n",
    "        return channel_citation_index\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "channel_citation_index(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.28571428571428"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discussion_rate(data):\n",
    "    \"\"\"\n",
    "    –û–±—Å—É–∂–¥–∞–µ–º–æ—Å—Ç—å –ø–æ—Å—Ç–æ–≤ (Discussion Rate)\n",
    "    (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ / –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –ø–æ–¥–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö) * 100% \n",
    "    \"\"\"\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            comment = [comment['sender_id'] for post in item['posts'] for comment in post.get('replies', [])]\n",
    "            \n",
    "            total_comment = len(comment)\n",
    "            unique_sender_ids = len(set(comment))\n",
    "            \n",
    "    if unique_sender_ids == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        discussion_rate = (total_comment / unique_sender_ids) * 100\n",
    "        return discussion_rate\n",
    "            \n",
    "\n",
    "discussion_rate(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimental Analysis for messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"–ú–æ—Å–∫–≤–∞\": {\n",
      "        \"users_count\": 4,\n",
      "        \"percent\": 50.0,\n",
      "        \"user_messages\": [\n",
      "            \"–ú—ã —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –±—ã—Å—Ç—Ä–æ —Å–∫—É—à–∞–ª–∏, –∞ –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–π —Ä–µ—à–∏–ª–∏, —á—Ç–æ –Ω–∞–µ–ª–∏—Å—å –∏ –±–æ–ª—å—à–µ –Ω–µ —Ö–æ—Ç–∏–º üòÇ\",\n",
      "            \"–ù–∞–¥–æ –±—Ä–∞—Ç—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ\",\n",
      "            \"–ü–æ–π–¥—É –∑–∞–ø—É—Å–∫–∞—Ç—å —Ä–∞–∫–µ—Ç—É –≤—Å–µ–º —Ö–æ—Ä–æ—à–µ–≥–æ –≤–µ—á–µ—Ä–∞ –∏ –¥–æ –Ω–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á\",\n",
      "            \"–°–∫–∞–∑–æ—á–Ω–æ–µ —Ñ–æ—Ç–æ, —Å–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏\"\n",
      "        ],\n",
      "        \"positive\": 0.5,\n",
      "        \"negative\": 0.25,\n",
      "        \"neutral\": 0.25\n",
      "    },\n",
      "    \"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥\": {\n",
      "        \"users_count\": 1,\n",
      "        \"percent\": 12.5,\n",
      "        \"user_messages\": [\n",
      "            \"–ú–Ω–µ –æ–Ω–∏ —Ç–æ–∂–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å\"\n",
      "        ],\n",
      "        \"positive\": 1.0,\n",
      "        \"negative\": 0.0,\n",
      "        \"neutral\": 0.0\n",
      "    },\n",
      "    \"–ë–∞–ª–∞—à–∏—Ö–∞\": {\n",
      "        \"users_count\": 1,\n",
      "        \"percent\": 12.5,\n",
      "        \"user_messages\": [\n",
      "            \"–£ –Ω–∞—Å —Ç–æ–∂–µ –±—ã—Å—Ç—Ä–æ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å.\"\n",
      "        ],\n",
      "        \"positive\": 0.0,\n",
      "        \"negative\": 1.0,\n",
      "        \"neutral\": 0.0\n",
      "    },\n",
      "    \"null\": {\n",
      "        \"users_count\": 1,\n",
      "        \"percent\": 12.5,\n",
      "        \"user_messages\": [\n",
      "            \"[id150437299|–ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∞ –ë–∞–ª—É–µ–≤–∞],  —Å –º–æ–ª–æ–∫–æ–º –∏–ª–∏ –∫–µ—Ñ–∏—Ä–æ–º 1% –æ–Ω–∏ –µ–¥—è—Ç—Å—è –∫–∞–∫ —Å–µ–º–µ—á–∫–∏ –°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±–∑–æ—Ä\"\n",
      "        ],\n",
      "        \"positive\": 1.0,\n",
      "        \"negative\": 0.0,\n",
      "        \"neutral\": 0.0\n",
      "    },\n",
      "    \"–°–µ—Ä—Ç–æ–ª–æ–≤–æ\": {\n",
      "        \"users_count\": 1,\n",
      "        \"percent\": 12.5,\n",
      "        \"user_messages\": [\n",
      "            \"–í–∞–∞–∞–∞—É, —Å–ø–∞—Å–∏–±–æ –∑–∞ —Ç–∞–∫–æ–µ —Ñ–æ—Ç–æ, –î–µ–Ω–∏—Å!! –ò –≤–∞–º –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–≥–æ –≤–µ—á–µ—Ä–∞!\"\n",
      "        ],\n",
      "        \"positive\": 1.0,\n",
      "        \"negative\": 0.0,\n",
      "        \"neutral\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def top_regions(data):\n",
    "    '''\n",
    "    –¢–æ–ø-20 —Ä–µ–≥–∏–æ–Ω–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    [—Ä–µ–≥–∏–æ–Ω | –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π | % | —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å]\n",
    "    '''\n",
    "    # https://huggingface.co/blanchefort/rubert-base-cased-sentiment –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "\n",
    "    city_users = {}\n",
    "\n",
    "    total_users = 0\n",
    "    \n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            for post in item['posts']:\n",
    "                for reply in post.get('replies', []):\n",
    "                    city = reply.get('city', 'Unknown')\n",
    "                    if city not in city_users:\n",
    "                        city_users[city] = []\n",
    "                    city_users[city].append(reply['sender_id'])\n",
    "                    total_users += 1\n",
    "\n",
    "    city_stats = {}\n",
    "    for city, users in city_users.items():\n",
    "        users_count = len(users)\n",
    "        percent = (users_count / total_users) * 100\n",
    "\n",
    "        user_messages = [post['text'] for post in item['posts'] for post in post['replies'] if post.get('city') == city and post['text'] is not None]\n",
    "        classified_messages = classifier(user_messages)\n",
    "        len_messages = len(classified_messages)\n",
    "        positive = len([i for i in classified_messages if i['label']=='POSITIVE']) / len_messages\n",
    "        negative = len([i for i in classified_messages if i['label']=='NEGATIVE']) / len_messages\n",
    "        neutral = len([i for i in classified_messages if i['label']=='NEUTRAL']) / len_messages\n",
    "\n",
    "        city_stats[city] = {\n",
    "            'users_count': users_count,\n",
    "            'percent': percent,\n",
    "            'user_messages': user_messages,\n",
    "            'positive': positive,\n",
    "            'negative': negative,\n",
    "            'neutral': neutral\n",
    "        }\n",
    "\n",
    "    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ø-20, —Å–æ—Ä—Ç–∏—Ä—É–µ–º city_stats –ø–æ users_count \n",
    "    sorted_city_stats = dict(sorted(city_stats.items(), key=lambda x: x[1]['users_count'], reverse=True)[:20])\n",
    "\n",
    "    top_regions = json.dumps(sorted_city_stats, indent=4, ensure_ascii=False)\n",
    "    return top_regions\n",
    "\n",
    "\n",
    "result = top_regions(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Promoter Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.5"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def net_promoter_score(data):\n",
    "    \"\"\"\n",
    "    –õ–æ—è–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (Net Promoter Score)\n",
    "    ((–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ - –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏) / –í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤) * 100%\n",
    "    \"\"\"\n",
    "    # https://huggingface.co/blanchefort/rubert-base-cased-sentiment –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "\n",
    "    for i in data:\n",
    "        for item in i['vk']:\n",
    "            total_messages = [post['text'] for post in item['posts'] for post in post['replies'] if post['text'] is not None]\n",
    "            len_total_messages = len(total_messages)\n",
    "            \n",
    "            classified_messages = classifier(total_messages)\n",
    "            positive_count = sum(1 for i in classified_messages if i['label'] == 'POSITIVE')\n",
    "            negative_count = sum(1 for i in classified_messages if i['label'] == 'NEGATIVE')\n",
    "\n",
    "    if len_total_messages > 0:\n",
    "        net_promoter_score = ((positive_count - negative_count) / len_total_messages) * 100\n",
    "        return net_promoter_score\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "net_promoter_score(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ –¥–ª–∏–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0-10': {'positive': 0, 'negative': 0, 'neutral': 0},\n",
       " '11-50': {'positive': 54.046635553825936,\n",
       "  'negative': 21.95435574663157,\n",
       "  'neutral': 23.9990086995425},\n",
       " '51-100': {'positive': 78.39615016850013,\n",
       "  'negative': 21.60384983149988,\n",
       "  'neutral': 0},\n",
       " '101-200': {'positive': 0, 'negative': 0, 'neutral': 0},\n",
       " '201+': {'positive': 0, 'negative': 0, 'neutral': 0}}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def character_length(data):\n",
    "    '''\n",
    "    –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ –¥–ª–∏–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    [–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ | —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å]\n",
    "    '''\n",
    "    lists = []\n",
    "    results = []\n",
    "    \n",
    "    # https://huggingface.co/blanchefort/rubert-base-cased-sentiment –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "    \n",
    "    # –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª–∏–Ω —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    dict_lengths = {1: '0-10', 2: '11-50', 3: '51-100', 4: '101-200', 5: '201+'}\n",
    "\n",
    "    comments_lengths = {\n",
    "        dict_lengths[1]: [],\n",
    "        dict_lengths[2]: [],\n",
    "        dict_lengths[3]: [],\n",
    "        dict_lengths[4]: [],\n",
    "        dict_lengths[5]: [] \n",
    "    }\n",
    "\n",
    "    for group in data:\n",
    "        for post in group['vk'][0]['posts']:\n",
    "            for reply in post['replies']:\n",
    "                if reply['text'] != None:\n",
    "                    comment_length = len(reply['text'])\n",
    "                    if comment_length < int(dict_lengths[1].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[1]].append(reply['text'])\n",
    "                    elif int(dict_lengths[1].split('-')[1])+1 <= comment_length <= int(dict_lengths[2].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[2]].append(reply['text'])\n",
    "                    elif int(dict_lengths[2].split('-')[1])+1 <= comment_length <= int(dict_lengths[3].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[3]].append(reply['text'])\n",
    "                    elif int(dict_lengths[3].split('-')[1])+1 <= comment_length <= int(dict_lengths[4].split('-')[1])+1:\n",
    "                        comments_lengths[dict_lengths[4]].append(reply['text'])\n",
    "                    else:\n",
    "                        comments_lengths[dict_lengths[5]].append(reply['text'])\n",
    "\n",
    "    for lengths in comments_lengths.keys():\n",
    "        lists.append([classifier(_) for _ in comments_lengths[lengths]])\n",
    "        \n",
    "    length_keys = dict_lengths.values()\n",
    "\n",
    "    for list in lists:\n",
    "        total_score = sum(dict['score'] for sublist in list for dict in sublist)\n",
    "\n",
    "        distribution = {'positive': 0, 'negative': 0, 'neutral': 0} \n",
    "        if total_score != 0:\n",
    "            for sublist in list:\n",
    "                for dict in sublist:\n",
    "                    distribution[dict['label'].lower()] += (dict['score'] / total_score) * 100\n",
    "\n",
    "        results.append(distribution)\n",
    "\n",
    "    comments_lengths_sentimentary = {}\n",
    "    for i, dist in zip(length_keys, results):\n",
    "        comments_lengths_sentimentary[i] = dist\n",
    "\n",
    "    return comments_lengths_sentimentary\n",
    "\n",
    "\n",
    "character_length(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–ø —ç–º–æ–¥–∑–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'üëé': 2, 'üî•': 1, '‚ù§': 1, 'üòÇ': 1, '‚ö°': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def top_emoji(data):\n",
    "    '''\n",
    "    –¢–æ–ø-5 —ç–º–æ–¥–∑–∏\n",
    "    [—ç–º–æ–¥–∑–∏ | –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —ç–º–æ–¥–∑–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö]\n",
    "    '''\n",
    "    def extract_emojis(text):\n",
    "        return ''.join(c for c in text if emoji.is_emoji(c))\n",
    "\n",
    "    emoji_counter = Counter()\n",
    "\n",
    "    for group in data:\n",
    "        for item in group['vk']:\n",
    "\n",
    "            messages = (reply['text'] for post in item['posts'] \n",
    "                        for reply in post['replies'] if reply['text'] is not None)\n",
    "            \n",
    "            for message in messages:\n",
    "                emojis = extract_emojis(message)\n",
    "                emoji_counter.update(emojis)\n",
    "\n",
    "    top_emojis = dict(emoji_counter.most_common(5))       \n",
    "    return top_emojis  \n",
    "\n",
    "\n",
    "top_emoji(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/nermakovaa/semester_4/SNA/SNA/data/new_data.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "    data = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'–ú–∞—Ä–∏–Ω–∞ –í–∫—É—Å–≤–∏–ª–ª': {'page_rank': 0.04746,\n",
       "  'id': 722219350,\n",
       "  'engagement_users': 28,\n",
       "  'net_promoter_score': 82.14285714285714},\n",
       " '–î–º–∏—Ç—Ä–∏–π –í–∫—É—Å–≤–∏–ª–ª': {'page_rank': 0.03822,\n",
       "  'id': 732871646,\n",
       "  'engagement_users': 24,\n",
       "  'net_promoter_score': 41.66666666666667},\n",
       " '–†–µ–≥–∏–Ω–∞ –í–∫—É—Å–≤–∏–ª–ª': {'page_rank': 0.03635,\n",
       "  'id': 449228789,\n",
       "  'engagement_users': 22,\n",
       "  'net_promoter_score': 77.27272727272727},\n",
       " '–°–≤–µ—Ç–ª–∞–Ω–∞ –°–æ–ª–Ω—ã—à–∫–æ': {'page_rank': 0.03604,\n",
       "  'id': 292391,\n",
       "  'engagement_users': 1,\n",
       "  'net_promoter_score': 0.0},\n",
       " '–í–∏–æ–ª–∞ –í–∫—É—Å–≤–∏–ª–ª': {'page_rank': 0.03297,\n",
       "  'id': 754226736,\n",
       "  'engagement_users': 22,\n",
       "  'net_promoter_score': 59.09090909090909},\n",
       " '–¢–∞—Ç—å—è–Ω–∞ –ë–∞–ª–∞–∫–∏—Ä–µ–≤–∞': {'page_rank': 0.02898,\n",
       "  'id': 588079193,\n",
       "  'engagement_users': 81,\n",
       "  'net_promoter_score': 73.33333333333333},\n",
       " '–ö–∞—Ç—è –ù–µ–¥–æ—Ä–µ–∑–æ–≤–∞': {'page_rank': 0.02807,\n",
       "  'id': 65412446,\n",
       "  'engagement_users': 37,\n",
       "  'net_promoter_score': 60.0},\n",
       " '–û–ª—å–≥–∞ –ì–∞–¥–∫–æ–≤–∞-–ö–Ω—è–∑–µ–≤–∞': {'page_rank': 0.02313,\n",
       "  'id': 116534950,\n",
       "  'engagement_users': 46,\n",
       "  'net_promoter_score': 66.66666666666666},\n",
       " '–¢–∞—Ç—å—è–Ω–∞ –ö–æ—Ä–æ–ª–µ–≤–∞': {'page_rank': 0.01942,\n",
       "  'id': 391295836,\n",
       "  'engagement_users': 33,\n",
       "  'net_promoter_score': 86.36363636363636},\n",
       " '–ê–∫–∏—Ç–∞ –ò–Ω—É': {'page_rank': 0.01727,\n",
       "  'id': 310156331,\n",
       "  'engagement_users': 18,\n",
       "  'net_promoter_score': 45.0}}"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "class PageRank:\n",
    "    '''\n",
    "    –¢–æ–ø-10 –∞–≤—Ç–æ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é –≤–æ–≤–ª–µ–∫–∞—Ç—å –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –¥–∏—Å–∫—É—Å—Å–∏—é\n",
    "    [–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å | –∑–Ω–∞—á–µ–Ω–∏–µ page rank]\n",
    "    '''\n",
    "    def __init__(self, data, top_authors=10):\n",
    "        self.data = data\n",
    "        self.top_authors = top_authors\n",
    "        self.sender_id, self.sender_info, self.connections = self.__get_data()\n",
    "        self.__get_file()\n",
    "        \n",
    "    def __get_data(self):\n",
    "        '''\n",
    "        sender_id - —É–∑–ª—ã (id –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)\n",
    "        sender_info - (—Å–ª–æ–≤–∞—Ä—å —Å id –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–ª—é—á–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–æ–≤–∞—Ä—è –∏–∑ first_name –∏ last_name)\n",
    "        connections - —Ä–µ–±—Ä–∞ (id-to-id)\n",
    "        '''\n",
    "        connections = []\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] != None:\n",
    "                post_connections = [(post['from']['id'], reply['sender_id']) for reply in post['replies']]\n",
    "                connections.extend(post_connections)\n",
    "\n",
    "        sender_id = list(set(sum(connections, ())))\n",
    "\n",
    "        sender_info = {}\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] is not None and post['from']['id'] in sender_id:\n",
    "                if post['from']['id'] not in sender_info:\n",
    "                    sender_info[post['from']['id']] = {\n",
    "                        'first_name': post['from']['first_name'],\n",
    "                        'last_name': post['from']['last_name']\n",
    "                    }\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if 'replies' in post:\n",
    "                for reply in post['replies']:\n",
    "                    if reply['sender_id'] in sender_id:\n",
    "                        if reply['sender_id'] not in sender_info:\n",
    "                            sender_info[reply['sender_id']] = {\n",
    "                                'first_name': reply['sender_name'],\n",
    "                                'last_name': reply['last_name']\n",
    "                            }\n",
    "\n",
    "        return sender_id, sender_info, connections\n",
    "\n",
    "    def page_rank(self):\n",
    "        '''\n",
    "        –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–ø–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π pagerank {722219350: 0.04746, 732871646: 0.03822 ...}\n",
    "        '''\n",
    "        G = nx.DiGraph()\n",
    "        [G.add_node(k, first_name = self.sender_info[k]['first_name'], last_name = self.sender_info[k]['last_name']) for k in self.sender_id]\n",
    "        G.add_edges_from(self.connections)\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=20) \n",
    "        \n",
    "        # pagerank - https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
    "        pr = nx.pagerank(G)\n",
    "        sorted_pr = sorted(pr.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        top_pr = sorted_pr[:self.top_authors] \n",
    "        \n",
    "        # —Ç–æ–ø 10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º pagerank\n",
    "        name_surname_dict = {k: round(v, 5) for k, v in top_pr}\n",
    "        \n",
    "        return name_surname_dict # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç id –∏ –∑–Ω–∞—á–µ–Ω–∏–µ pagerank {722219350: 0.04746, 732871646: 0.03822 ...}\n",
    "    \n",
    "    def __get_file(self):\n",
    "        '''\n",
    "        –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ pagerank\n",
    "        '''\n",
    "        # spring_layout - https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "        G = nx.DiGraph()\n",
    "        [G.add_node(k, first_name=self.sender_info[k]['first_name'], last_name=self.sender_info[k]['last_name']) for k in self.sender_id]\n",
    "        G.add_edges_from(self.connections)\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=20)\n",
    "\n",
    "        pr = nx.pagerank(G)\n",
    "        sorted_pr = sorted(pr.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_pr = sorted_pr[:self.top_authors]\n",
    "        top_ids = [id for id, pr in top_pr]\n",
    "        top_nodes = {node: G.nodes[node]['first_name'] + ' ' + G.nodes[node]['last_name'] for node in dict(top_pr).keys()}\n",
    "\n",
    "        node_colors = ['#FF5558' if node in top_ids else \"#27BBBD\" for node in G.nodes()]\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        nx.draw_networkx_labels(G, pos,\n",
    "                                labels=top_nodes,\n",
    "                                font_color='#333335',\n",
    "                                font_size=10,\n",
    "                                bbox=dict(facecolor='white', edgecolor='white', boxstyle='square'))\n",
    "        nx.draw(G, pos,\n",
    "                nodelist=list(pr.keys()),\n",
    "                node_size=[v * 20000 for v in pr.values()],\n",
    "                with_labels=False,\n",
    "                node_color=node_colors,\n",
    "                edge_color='#27BBBD',\n",
    "                width=0.2)\n",
    "        \n",
    "        current_dir = os.getcwd()\n",
    "        file_path = os.path.join(current_dir, 'data/PageRank.png')\n",
    "        plt.savefig(file_path) \n",
    "        plt.close()  \n",
    "        \n",
    "    def get_table(self):\n",
    "        '''\n",
    "        –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã —Ç–æ–ø-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ PageRank\n",
    "        '''\n",
    "        result_dict = {}\n",
    "        for k, v in self.page_rank().items():\n",
    "            name = self.sender_info[k]['first_name'] + ' ' + self.sender_info[k]['last_name']\n",
    "            result_dict[name] = {\n",
    "                'page_rank': self.page_rank()[k],\n",
    "                'id': k\n",
    "            }\n",
    "\n",
    "        for key, value in result_dict.items():\n",
    "            id_to_find = value['id']\n",
    "            count = 0\n",
    "            for tpl in self.connections:\n",
    "                if id_to_find in tpl:\n",
    "                    count += 1\n",
    "            value['engagement_users'] = count\n",
    "        \n",
    "        for key, value in result_dict.items():\n",
    "            value['comments'] = []  \n",
    "            \n",
    "        id = [value['id'] for key, value in result_dict.items()]\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            for replies in post['replies']:\n",
    "                for key, value in result_dict.items():\n",
    "                    if replies['sender_id'] == value['id']:\n",
    "                        value['comments'].append(replies['text'])\n",
    "                        \n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "        \n",
    "        for key, value in result_dict.items():\n",
    "            pos_count = 0\n",
    "            neg_count = 0\n",
    "            comments = value['comments']\n",
    "\n",
    "            for comment in comments:\n",
    "                sentiment = classifier(comment)\n",
    "                if sentiment[0]['label'] == 'POSITIVE':\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "\n",
    "            if (pos_count + neg_count) != 0:\n",
    "                nps = (pos_count / (pos_count + neg_count)) * 100 # nps = –ª–æ—è–ª—å–Ω–æ—Å—Ç—å\n",
    "                value['net_promoter_score'] = nps\n",
    "            else:\n",
    "                0     \n",
    "                                    \n",
    "        for key in result_dict:\n",
    "            if 'comments' in result_dict[key]:\n",
    "                del result_dict[key]['comments']\n",
    "        \n",
    "        return result_dict # {'–ú–∞—Ä–∏–Ω–∞ –í–∫—É—Å–≤–∏–ª–ª': {'page_rank': 0.04746,  'id': 722219350,  'engagement_users': 28,  'net_promoter_score': 82.14285714285714},   \n",
    "        \n",
    "\n",
    "table = PageRank(data)\n",
    "table.get_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'–¢–∞—Ç—å—è–Ω–∞ –ë–∞–ª–∞–∫–∏—Ä–µ–≤–∞': {'page_rank': 0.07433,\n",
       "  'id': 588079193,\n",
       "  'engagement_users': 81,\n",
       "  'positive': 73.33333333333333,\n",
       "  'negative': 8.88888888888889,\n",
       "  'neutral': 17.77777777777778},\n",
       " '–û–ª—å–≥–∞ –ì–∞–¥–∫–æ–≤–∞-–ö–Ω—è–∑–µ–≤–∞': {'page_rank': 0.0409,\n",
       "  'id': 116534950,\n",
       "  'engagement_users': 46,\n",
       "  'positive': 66.66666666666666,\n",
       "  'negative': 29.166666666666668,\n",
       "  'neutral': 4.166666666666666},\n",
       " '–Æ–ª–∏—è –ö–æ—Ä–Ω–∏–µ–Ω–∫–æ': {'page_rank': 0.02592,\n",
       "  'id': 11221120,\n",
       "  'engagement_users': 12,\n",
       "  'positive': 61.53846153846154,\n",
       "  'negative': 15.384615384615385,\n",
       "  'neutral': 23.076923076923077},\n",
       " '–ï–≤–≥–µ–Ω–∏—è –°–∞–Ω–Ω–∏–∫–æ–≤–∞': {'page_rank': 0.02282,\n",
       "  'id': 2057854,\n",
       "  'engagement_users': 29,\n",
       "  'positive': 41.66666666666667,\n",
       "  'negative': 16.666666666666664,\n",
       "  'neutral': 41.66666666666667},\n",
       " '–ì–∞–ª–∏–Ω–∞ –ü–æ–≥–æ—Ä–µ–ª—å—á–µ–Ω–∫–æ': {'page_rank': 0.02226,\n",
       "  'id': 151635555,\n",
       "  'engagement_users': 52,\n",
       "  'positive': 50.0,\n",
       "  'negative': 12.5,\n",
       "  'neutral': 37.5},\n",
       " '–í–µ—Ä–∞ –ú–∏—Ö–∞–π–ª–æ–≤–Ω–∞': {'page_rank': 0.01697,\n",
       "  'id': 635311641,\n",
       "  'engagement_users': 27,\n",
       "  'positive': 70.0,\n",
       "  'negative': 10.0,\n",
       "  'neutral': 20.0},\n",
       " '–¢–∞—Ç—å—è–Ω–∞ –ê–ª–µ–∫—Å–µ–µ–≤–∞': {'page_rank': 0.01644,\n",
       "  'id': 239932827,\n",
       "  'engagement_users': 30,\n",
       "  'positive': 46.15384615384615,\n",
       "  'negative': 23.076923076923077,\n",
       "  'neutral': 30.76923076923077},\n",
       " '–î–∞—Ä—å—è –®—É–Ω–∏–∫–æ–≤–∞': {'page_rank': 0.01299,\n",
       "  'id': 60265399,\n",
       "  'engagement_users': 13,\n",
       "  'positive': 66.66666666666666,\n",
       "  'negative': 33.33333333333333,\n",
       "  'neutral': 0.0},\n",
       " '–ù–∞—Ç–∞–ª—å—è –ö–æ—Å—Ç–æ–º–∞—Ö–∏–Ω–∞': {'page_rank': 0.01271,\n",
       "  'id': 66139334,\n",
       "  'engagement_users': 24,\n",
       "  'positive': 66.66666666666666,\n",
       "  'negative': 0.0,\n",
       "  'neutral': 33.33333333333333},\n",
       " '–¢–∞—Ç—å—è–Ω–∞ –ö–æ—Ä–æ–ª–µ–≤–∞': {'page_rank': 0.01112,\n",
       "  'id': 391295836,\n",
       "  'engagement_users': 33,\n",
       "  'positive': 86.36363636363636,\n",
       "  'negative': 0.0,\n",
       "  'neutral': 13.636363636363635}}"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "class BetweennessCentralityRank:\n",
    "    '''\n",
    "    –¢–æ–ø-10 –∞–≤—Ç–æ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é –≤–æ–≤–ª–µ–∫–∞—Ç—å –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –¥–∏—Å–∫—É—Å—Å–∏—é\n",
    "    [–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å | –∑–Ω–∞—á–µ–Ω–∏–µ page rank]\n",
    "    '''\n",
    "    def __init__(self, data, top_authors=10):\n",
    "        self.data = data\n",
    "        self.top_authors = top_authors\n",
    "        self.sender_id, self.sender_info, self.connections = self.__get_data()\n",
    "        self.__get_file()\n",
    "        \n",
    "    def __get_data(self):\n",
    "        '''\n",
    "        sender_id - —É–∑–ª—ã (id –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)\n",
    "        sender_info - (—Å–ª–æ–≤–∞—Ä—å —Å id –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–ª—é—á–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–æ–≤–∞—Ä—è –∏–∑ first_name –∏ last_name)\n",
    "        connections - —Ä–µ–±—Ä–∞ (id-to-id)\n",
    "        '''\n",
    "        connections = []\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] != None:\n",
    "                post_connections = [(post['from']['id'], reply['sender_id']) for reply in post['replies']]\n",
    "                connections.extend(post_connections)\n",
    "\n",
    "        sender_id = list(set(sum(connections, ())))\n",
    "\n",
    "        sender_info = {}\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] is not None and post['from']['id'] in sender_id:\n",
    "                if post['from']['id'] not in sender_info:\n",
    "                    sender_info[post['from']['id']] = {\n",
    "                        'first_name': post['from']['first_name'],\n",
    "                        'last_name': post['from']['last_name']\n",
    "                    }\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if 'replies' in post:\n",
    "                for reply in post['replies']:\n",
    "                    if reply['sender_id'] in sender_id:\n",
    "                        if reply['sender_id'] not in sender_info:\n",
    "                            sender_info[reply['sender_id']] = {\n",
    "                                'first_name': reply['sender_name'],\n",
    "                                'last_name': reply['last_name']\n",
    "                            }\n",
    "\n",
    "        return sender_id, sender_info, connections\n",
    "\n",
    "    def page_rank(self):\n",
    "        '''\n",
    "        –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–ø–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π betweenness_centrality_rank {722219350: 0.04746, 732871646: 0.03822 ...}\n",
    "        '''\n",
    "        G = nx.DiGraph()\n",
    "        [G.add_node(k, first_name = self.sender_info[k]['first_name'], last_name = self.sender_info[k]['last_name']) for k in self.sender_id]\n",
    "        G.add_edges_from(self.connections)\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=20) \n",
    "        \n",
    "        # pagerank - https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
    "        centrality = nx.betweenness_centrality(G)\n",
    "        sorted_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        top_centrality = sorted_centrality[:self.top_authors] \n",
    "        \n",
    "        # —Ç–æ–ø 10 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º pagerank\n",
    "        name_surname_dict = {k: round(v, 5) for k, v in top_centrality}\n",
    "        \n",
    "        return name_surname_dict # –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç id –∏ –∑–Ω–∞—á–µ–Ω–∏–µ pagerank {722219350: 0.04746, 732871646: 0.03822 ...}    \n",
    "    \n",
    "    def __get_file(self):\n",
    "        '''\n",
    "        –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ pagerank\n",
    "        '''\n",
    "        # spring_layout - https://networkx.org/documentation/stable/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "        G = nx.DiGraph()\n",
    "        [G.add_node(k, first_name=self.sender_info[k]['first_name'], last_name=self.sender_info[k]['last_name']) for k in self.sender_id]\n",
    "        G.add_edges_from(self.connections)\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=20)\n",
    "\n",
    "        centrality = nx.betweenness_centrality(G)\n",
    "        sorted_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "        top_centrality = sorted_centrality[:self.top_authors] \n",
    "        top_ids = [id for id, pr in top_centrality]\n",
    "        top_nodes = {node: G.nodes[node]['first_name'] + ' ' + G.nodes[node]['last_name'] for node in dict(top_centrality).keys()}\n",
    "\n",
    "        node_colors = ['#FF5558' if node in top_ids else '#27BBBD' for node in G.nodes()]\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        nx.draw_networkx_labels(G, pos,\n",
    "                                labels=top_nodes,\n",
    "                                font_color='#333335',\n",
    "                                font_size=10,\n",
    "                                bbox=dict(facecolor='white', edgecolor='white', boxstyle='square'))\n",
    "        nx.draw(G, pos,\n",
    "                nodelist=list(centrality.keys()),\n",
    "                node_size=[v * 20000 for v in centrality.values()],\n",
    "                with_labels=False,\n",
    "                node_color=node_colors,\n",
    "                edge_color='#27BBBD',\n",
    "                width=0.2)\n",
    "        \n",
    "        current_dir = os.getcwd()\n",
    "        file_path = os.path.join(current_dir, 'data/BetweennessCentralityRank.png')\n",
    "        plt.savefig(file_path) \n",
    "        plt.close()      \n",
    "    \n",
    "    def get_table(self):\n",
    "        '''\n",
    "        –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã —Ç–æ–ø-–∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ BetweennessCentralityRank\n",
    "        '''\n",
    "        result_dict = {}\n",
    "        for k, v in self.page_rank().items():\n",
    "            name = self.sender_info[k]['first_name'] + ' ' + self.sender_info[k]['last_name']\n",
    "            result_dict[name] = {\n",
    "                'page_rank': self.page_rank()[k],\n",
    "                'id': k\n",
    "            }\n",
    "\n",
    "        for key, value in result_dict.items():\n",
    "            id_to_find = value['id']\n",
    "            count = 0\n",
    "            for tpl in self.connections:\n",
    "                if id_to_find in tpl:\n",
    "                    count += 1\n",
    "            value['engagement_users'] = count\n",
    "        \n",
    "        for key, value in result_dict.items():\n",
    "            value['comments'] = []  \n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            for replies in post['replies']:\n",
    "                for key, value in result_dict.items():\n",
    "                    if replies['sender_id'] == value['id']:\n",
    "                        value['comments'].append(replies['text'])\n",
    "                        \n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "        \n",
    "        for key, value in result_dict.items():\n",
    "            comments = value['comments']\n",
    "            \n",
    "            pos_count = 0\n",
    "            neg_count = 0\n",
    "            neu_count = 0\n",
    "\n",
    "            for comment in comments:\n",
    "                sentiment = classifier(comment)\n",
    "                label = sentiment[0]['label']\n",
    "\n",
    "                if label == 'POSITIVE':\n",
    "                    pos_count += 1\n",
    "                elif label == 'NEGATIVE':\n",
    "                    neg_count += 1\n",
    "                else:\n",
    "                    neu_count += 1\n",
    "            \n",
    "            total_count = pos_count + neg_count + neu_count\n",
    "            value['positive'] = pos_count / total_count * 100\n",
    "            value['negative'] = neg_count / total_count * 100\n",
    "            value['neutral'] = neu_count / total_count * 100\n",
    "            \n",
    "        for key in result_dict:\n",
    "            if 'comments' in result_dict[key]:\n",
    "                del result_dict[key]['comments']\n",
    "        \n",
    "        return result_dict # {'–¢–∞—Ç—å—è–Ω–∞ –ë–∞–ª–∞–∫–∏—Ä–µ–≤–∞': {'page_rank': 0.07433, 'id': 588079193,  'engagement_users': 81,  'positive': 73.33333333333333,  'negative': 8.88888888888889,  'neutral': 17.77777777777778},\n",
    "    \n",
    "        \n",
    "table = BetweennessCentralityRank(data)\n",
    "table.get_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–ø-5 –∞–≤—Ç–æ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/nermakovaa/semester_4/SNA/SNA/data/new_data.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "    data = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'–ì–∞–ª–∏–Ω–∞ –ü–æ–≥–æ—Ä–µ–ª—å—á–µ–Ω–∫–æ': {'get_message': 10,\n",
       "  'engagement_rate_by_reach': 4.31,\n",
       "  'net_promoter_score': 65.0},\n",
       " '–ï–≤–≥–µ–Ω–∏—è –°–∞–Ω–Ω–∏–∫–æ–≤–∞': {'get_message': 7,\n",
       "  'engagement_rate_by_reach': 2.635,\n",
       "  'net_promoter_score': 68.42},\n",
       " '–¢–∞—Ç—å—è–Ω–∞ –ë–∞–ª–∞–∫–∏—Ä–µ–≤–∞': {'get_message': 6,\n",
       "  'engagement_rate_by_reach': 3.108,\n",
       "  'net_promoter_score': 65.91},\n",
       " '–û–ª—å–≥–∞ –ì–∞–¥–∫–æ–≤–∞-–ö–Ω—è–∑–µ–≤–∞': {'get_message': 5,\n",
       "  'engagement_rate_by_reach': 2.162,\n",
       "  'net_promoter_score': 68.18},\n",
       " '–¢–∞—Ç—å—è–Ω–∞ –ê–ª–µ–∫—Å–µ–µ–≤–∞': {'get_message': 4,\n",
       "  'engagement_rate_by_reach': 1.727,\n",
       "  'net_promoter_score': 44.44}}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "class InfluencerTable:\n",
    "    '''\n",
    "    –¢–æ–ø-5 –∞–≤—Ç–æ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "    [–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å | –ø–æ—Å—Ç–æ–≤ –≤ –≥—Ä—É–ø–ø–µ | –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å | –ª–æ—è–ª—å–Ω–æ—Å—Ç—å]\n",
    "    '''\n",
    "    def __init__(self, data, person=5):\n",
    "        self.data = data\n",
    "        self.person = person\n",
    "        \n",
    "    def __get_data(self):\n",
    "        dt = {}  \n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] is not None:\n",
    "                post_id = post['from']['id']\n",
    "                if post_id not in dt:\n",
    "                    dt[post_id] = {\n",
    "                        'first_name': post['from']['first_name'],\n",
    "                        'last_name': post['from']['last_name'],\n",
    "                        'likes': post['reactions'][0]['count'],\n",
    "                        'messages': 1,\n",
    "                        'comments': [reply['text'] for reply in post['replies']],\n",
    "                        'reposts': post['forwards'],\n",
    "                        'followers': self.data['vk'][0]['membersCount']\n",
    "                    }\n",
    "                else:  \n",
    "                    dt[post_id]['messages'] += 1\n",
    "                    dt[post_id]['likes'] += post['reactions'][0]['count']\n",
    "                    dt[post_id]['reposts'] += post['forwards']\n",
    "                    dt[post_id]['comments'].extend([reply['text'] for reply in post['replies']])\n",
    "                \n",
    "        return dt\n",
    "            \n",
    "    def get_name(self):\n",
    "        '''\n",
    "        –§–ò–û –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤\n",
    "        '''\n",
    "        self.data = self.__get_data()\n",
    "        sorted_data = sorted(self.data.values(), key=lambda x: x['messages'], reverse=True)\n",
    "        authors_names = {v['first_name'] + ' ' + v['last_name']: v['messages'] for v in sorted_data[:self.person]}\n",
    "        return authors_names # —Å–ª–æ–≤–∞—Ä—å {'first_name last_name': messages}, –≥–¥–µ messages - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤, –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\n",
    "    \n",
    "    def engagement_rate_by_reach(self):\n",
    "        '''\n",
    "        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (Engagement Rate By Reach)\n",
    "        (–û–±—â–µ–µ —á–∏—Å–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞) * 100%\n",
    "        '''\n",
    "        sorted_data = sorted(self.data.values(), key=lambda x: x['messages'], reverse=True)\n",
    "\n",
    "        engagement_rates = {\n",
    "            v['first_name'] + ' ' + v['last_name']: round(((v['likes'] + v['reposts'] + len(v['comments'])) / v['followers']) * 1000, 3) \n",
    "            for v in sorted_data[:self.person] if v['followers'] != 0\n",
    "        }\n",
    "        return engagement_rates # —Å–ª–æ–≤–∞—Ä—å {'first_name last_name': engagement_rate_by_reach}, engagement_rate_by_reach - –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å\n",
    "    \n",
    "    def net_promoter_score(self):\n",
    "        \"\"\"\n",
    "        –õ–æ—è–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (Net Promoter Score)\n",
    "        ((–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ - –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏) / –í—Å–µ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤) * 100%\n",
    "        \"\"\"\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\") \n",
    "        \n",
    "        top_users = sorted(self.data.values(), key=lambda x: x['messages'], reverse=True)[:self.person]\n",
    "        loyalty_scores = []\n",
    "        \n",
    "        for user in top_users:\n",
    "            positive_count = 0\n",
    "            negative_count = 0\n",
    "            \n",
    "            for comment in user['comments']:\n",
    "                classified_comment = classifier(comment)\n",
    "                if classified_comment[0]['label'] == 'POSITIVE':\n",
    "                    positive_count += 1\n",
    "                elif classified_comment[0]['label'] == 'NEGATIVE':\n",
    "                    negative_count += 1\n",
    "            \n",
    "            total_comments = len(user['comments'])\n",
    "            if total_comments > 0:\n",
    "                loyalty_score = ((positive_count - negative_count) / total_comments) * 100\n",
    "                loyalty_scores.append((user['first_name'] + ' ' + user['last_name'], round(loyalty_score, 2)))\n",
    "        \n",
    "        return sorted(loyalty_scores, key=lambda x: x[1], reverse=True) # —Å–ª–æ–≤–∞—Ä—å {'first_name last_name': net_promoter_score}, net_promoter_score - –ª–æ—è–ª—å–Ω–æ—Å—Ç—å\n",
    "\n",
    "    def influencer_table_result(self):\n",
    "        '''\n",
    "        –¢–æ–ø-5 –∞–≤—Ç–æ—Ä–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "        '''\n",
    "        data_dict = {}\n",
    "        \n",
    "        names = self.get_name()\n",
    "        engagement_rate = self.engagement_rate_by_reach()\n",
    "        nps = self.net_promoter_score()\n",
    "        \n",
    "        nps_dict = {name: rating for name, rating in nps}\n",
    "        \n",
    "        for name, messages in names.items():\n",
    "            data_dict[name] = {\n",
    "                'get_message': messages,\n",
    "                'engagement_rate_by_reach': engagement_rate.get(name, 0),\n",
    "                'net_promoter_score': nps_dict.get(name, 0)\n",
    "            }\n",
    "        \n",
    "        return data_dict # {'–ì–∞–ª–∏–Ω–∞ –ü–æ–≥–æ—Ä–µ–ª—å—á–µ–Ω–∫–æ': {'get_message': 10,  'engagement_rate_by_reach': 4.31,  'net_promoter_score': 65.0}, '–ï–≤–≥–µ–Ω–∏—è –°–∞–Ω–Ω–∏–∫–æ–≤–∞': ...}\n",
    "    \n",
    "us = InfluencerTable(data)\n",
    "us.influencer_table_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–ø –ø–æ—Å—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º —É—Ä–æ–≤–Ω–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/nermakovaa/semester_4/SNA/SNA/data/new_data.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "    data = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'–î—Ä—É–∑—å—è, –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã —Å –ø–æ–∫—É–ø–∫–æ–π –∫—É—Ä–∏–Ω—ã—Ö –∫—Ä—ã–ª—ã—à–µ–∫ –≤–æ –í–∫—É—Å–í–∏–ª–ª!\\n\\n–ü–æ–∫—É–ø–∞–ª–∞ –Ω–µ –ø–æ —É—Ü–µ–Ω–∫–µ, –¥–∞—Ç–∞ —Å–≤–µ–∂–∞—è –∏–∑ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö. –í—á–µ—Ä–∞ –ø—Ä–∏–≤–µ–∑–ª–∏ —Å –∑–∞–ø–∞—Ö–æ–º —Ö–ª–æ—Ä–∞ –∏–ª–∏ —á–µ–≥–æ-—Ç–æ –ø–æ–¥–æ–±–Ω–æ–≥–æ, –∞ —Å–µ–≥–æ–¥–Ω—è —Ä–∞–Ω–Ω–∏–º —É—Ç—Ä–æ–º –∫—Ä—ã–ª—ã—à–∫–∏ —É–∂–µ –±—ã–ª–∏ —Ç—É—Ö–ª—ã–µ (—Ö–æ—Ç—è –æ–Ω–∏ –µ—â—ë –≤ —Ä–∞–º–∫–∞—Ö –æ–±–µ—â–∞–Ω–Ω–æ–≥–æ —Å—Ä–æ–∫–∞ –≥–æ–¥–Ω–æ—Å—Ç–∏).\\n\\n[club19817989|–í–∫—É—Å–í–∏–ª–ª. –ó–¥–µ—Å—å –ø–æ–ª–µ–∑–Ω–æ–µ –≤–∫—É—Å–Ω–æ] , —Å–ª–µ–¥–∏—Ç–µ –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ–º, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞. –ê —Ç–∞–∫–∂–µ —Å–ª–µ–¥–∏—Ç–µ –∑–∞ —Ä–∞–±–æ—Ç–æ–π —Å–ª—É–∂–±—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏, –ø–æ–ª–Ω–∞—è –Ω–µ–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å!!! \\n–ó–∞–∫–∞–∑ - ‚Ññ302666617-1\\n–ü—Ä–æ—à—É –æ—Ñ–æ—Ä–º–∏—Ç—å –≤–æ–∑–≤—Ä–∞—Ç –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ —Ö–æ—á–µ—Ç—Å—è —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –ø–æ—Ö–æ–¥ –≤ –º–∞–≥–∞–∑–∏–Ω. \\n–ö—Ä—ã–ª—ã—à–∫–∏ –≤ –ø–æ–º–æ–π–∫–µ –≥–¥–µ –∏–º –∏ –º–µ—Å—Ç–æ.\\n\\nüôÑupd –í –∏—Ç–æ–≥–µ –≤–µ—Ä–Ω—É–ª–∞ —Ç—É—Ö–ª—ã–µ –∫—Ä—ã–ª—ã—à–∫–∏ –≤ –º–∞–≥–∞–∑–∏–Ω —Ç–∞–∫ –∫–∞–∫ –≤ –æ–Ω–ª–∞–π–Ω –≤–æ–∑–≤—Ä–∞—Ç–µ –æ—Ç–∫–∞–∑–∞–ª–∏. \\n–°–µ—Ä–≤–∏—Å –∏ –ø—Ä–æ–¥—É–∫—Ç—ã —Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏–µ ü§¢ü§Æ': {'first_name': '–ù–∞—Ç–∞–ª–∏—è –ú–∏–ª–∞–Ω–æ',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.01790601898038012},\n",
       " '–í–æ—Ç —Ç–∞–∫–∏–µ —Å—Ç—Ä–∏–ø—Å—ã, –æ–¥–Ω–∏ –æ–±—Ä–µ–∑–∫–∏': {'first_name': '–õ—é–¥–º–∏–ª–∞ –ë–æ–ª—å—à–∞–∫–æ–≤–∞',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.020464021691862993},\n",
       " '–£ –≤–∞—Ä–µ–Ω–æ–π –∫–∞—Ä—Ç–æ—à–∫–∏ –Ω–µ–¥–æ–≤–µ—Å, –µ—Å–ª–∏ –µ—â–µ —É–ø–∞–∫–æ–≤–∫—É –≤—ã—á–µ—Å—Ç—å, —Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ç–∞–∫ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç, —Ü–µ–ª–æ–π –∫–∞—Ä—Ç–æ—à–µ—á–∫–∏ü•∫–æ–±–∏–¥–Ω–æ —Å —É—á–µ—Ç–æ–º —Ç–æ–≥–æ —á—Ç–æ 500 –≥—Ä–∞–º –∫–∞—Ä—Ç–æ—à–∫–∏ –ø—Ä–æ–¥–∞—é—Ç –ø–æ —Ü–µ–Ω–µ 10 –∫–≥\\n\\nP.S. –Ø –Ω–µ –º–∞–Ω—å—è–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –≥—Ä–∞–º–º–æ–≤–∫–∏, –Ω–æ –µ–¥—É –≤–∑–≤–µ—à–∏–≤–∞—é, —Ç–∞–∫ –∫–∞–∫ –∑–∞–Ω–∏–º–∞—é—Å—å —Å–ø–æ—Ä—Ç–æ–º –∏ –Ω—É–∂–Ω–æ –Ω–∞–±—Ä–∞—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –ë–ñ–£\\n\\n–ù–∞–ª–æ–∂–∏–ª–∞ –≤ —Ç–∞—Ä–µ–ª–∫—É —Ä–æ–≤–Ω–æ 250 –≥—Ä–∞–º–º, –≤–∏–∑—É–∞–ª—å–Ω–æ –≤–∏–∂—É, —á—Ç–æ –≤ —É–ø–∞–∫–æ–≤–∫–µ –æ—Å—Ç–∞–ª–æ—Å—å —è–≤–Ω–æ –Ω–µ –ø–æ–ª–æ–≤–∏–Ω–∞ –ø–æ—Ä—Ü–∏–∏, –≤—ã—Å—ã–ø–∞–ª–∞ –≤—Å–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, —Ä–µ—à–∏–ª–∞ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –≤–¥—Ä—É–≥ –≥–ª–∞–∑–æ–º–µ—Ä –ø–æ–¥–≤–µ–ª\\n\\n–ù–µ—Ç, –Ω–µ –ø–æ–¥–≤–µ–ª': {'first_name': 'Valeriya Mikhaylovna',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.02558002711482874},\n",
       " '–°–∫–∞–∂–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫—É–¥–∞ –¥–µ–ª—Å—è –±—ç–±–∏ –∫–∞—Ä—Ç–æ—Ñ–µ–ª—å –∏–∑ –°–ü–ë? ü•∫\\n\\n–Ø –æ—á–µ–Ω—å –ª—é–±–ª—é –∫–∞—Ä—Ç–æ—à–∫—É, –Ω–æ –æ—á–µ–Ω—å –Ω–µ –ª—é–±–ª—é –µ–µ —á–∏—Å—Ç–∏—Ç—åüòÅ\\n\\n–∏ –≤–æ—Ç –∫–∞—Ä—Ç–æ—Ñ–µ–ª—å –ø—Ä–æ–ø–∞–ª –º–µ—Å—è—Ü–∞ 2-3 –∏ —Å —Ç–µ—Ö –ø–æ—Ä —è –µ–≥–æ –Ω–µ –µ–º, –∞ —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã': {'first_name': '–ê–Ω–∞—Å—Ç–∞—Å–∏—è –í–µ—Ä—à–∏–Ω–∏–Ω–∞',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.020464021691862993},\n",
       " '–í—á–µ—Ä–∞ –∫—É–ø–∏–ª–∏ —Ç–æ—Ä—Ç–∏–∫ –¥–æ—á–µ–Ω—å–∫–µ –Ω–∞ –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –∏ –≤ –Ω—ë–º –∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é –ø–æ–ø–∞–ª—Å—è –∫—É—Å–æ–∫ –¥–µ—Ä–µ–≤—è–Ω–Ω–æ–π —â–µ–ø–∫–∏(((—Ö–æ—Ä–æ—à–æ, —á—Ç–æ —ç—Ç–æ—Ç –∫—É—Å–æ–∫ –Ω–µ –ø–æ–ø–∞–ª—Å—è —Ä–µ–±—ë–Ω–∫—É. –ö–∞—Ä—Ç–∞ 0134185': {'first_name': '–ë–µ–ª—ã–π –°–Ω–µ–≥',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.01790601898038012},\n",
       " '–í—á–µ—Ä–∞ –≤ 23.30 –ø—ã—Ç–∞–ª–∞—Å—å –ø–æ–º–µ–Ω—è—Ç—å –õ–ü ,–º–Ω–µ –Ω–∞–ø–∏—Å–∞–ª–∏ —á—Ç–æ –Ω–µ—Ç –ø–æ–∫—É–ø–∫–∏ –Ω–∞ 500 —Ä—É–±–ª–µ–π. –°–µ–≥–æ–¥–Ω—è —É—Ç—Ä–æ–º —Å–º–æ–≥–ª–∞ –ø–æ–º–µ–Ω—è—Ç—å. –£–∂–µ –Ω–µ –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ —Ç–∞–∫–∞—è –µ—Ä—É–Ω–¥–∞. –ü–æ–∑–≤–æ–Ω–∏–ª–∞ –Ω–∞ –ì–õ ...–¥–æ–±—Ä–∞—è –¥–µ–≤—É—à–∫–∞ ,–ª–∞—Å–∫–æ–≤–æ –æ—Ç–≤–µ—Ç–∏–ª–∞ —á—Ç–æ –Ω–∞–¥–æ –±—ã–ª–æ —Å–¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ –ì–õ .–ò–ª–∏ –ø–æ–∑–≤–æ–Ω–∏—Ç—å –≤ 23.30 —Ç–æ–≥–¥–∞ –±—ã –æ–Ω–∏ –ø–æ–º–æ–≥–ª–∏...–∞ —Ç–µ–ø–µ—Ä—å –∫–∞–∫ –µ—Å—Ç—å .–í—Å—ë –∫–æ–Ω–µ—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –Ω–æ –æ—Å–∞–¥–æ–∫ –Ω–µ –æ—á–µ–Ω—å. –ü—Ä–æ—Å—Ç–æ —Ö–æ—á–µ—Ç—Å—è –∑–Ω–∞—Ç—å ,–∫–∞–∫–æ–≥–æ —Ö—Ä–µ–Ω–∞ —è –¥–æ–ª–∂–Ω–∞ –Ω–µ—Ä–≤–Ω–∏—á–∞—Ç—å –∏–∑-–∑–∞ —Å–±–æ–µ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è? –ü–æ—á–µ–º—É —è –¥–æ–ª–∂–Ω–∞ –¥–µ–ª–∞—Ç—å —Å–∫—Ä–∏–Ω—ã –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—å —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç—Å—Ç–æ—è–≤ 16 —á–∞—Å–æ–≤ –Ω–∞ –Ω–æ–≥–∞—Ö....–°–µ–≥–æ–¥–Ω—è –ø–æ—Ç—Ä–∞—Ç–∏–ª–∞ 10 –º–∏–Ω—É—Ç –±–µ–º—ã—Å–ª–µ–Ω–æ –æ–∂–∏–¥–∞—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ –ì–õ ,—á—Ç–æ–±—ã —É—Å–ª—ã—à–∞—Ç—å —á—Ç–æ —è –ª–æ—Ö))))) –í—Å–µ–º –¥–æ–±—Ä–æ–≥–æ —É—Ç—Ä–∞! –°–ø–∞—Å–∏–±–æ –í–∫—É—Å–≤–∏–ª–ª, –∑–∞ –æ—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ': {'first_name': '–ú–∞—Ä–∏—è –¢—Ä—É—à–∫–∏–Ω–∞',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.014069014913155807},\n",
       " '–û—á–µ–Ω—å –∂–¥–∞–ª–∏ –∫—É—Ä–∏–Ω—ã–µ —Å–µ—Ä–¥–µ—á–∫–∏ –∏ –æ–¥–Ω–∞ —É–ø–∞–∫–æ–≤–∫–∞ –æ–∫–∞–∑–∞–ª–∞—Å—å –Ω–µ—Å–≤–µ–∂–µ–π. –í–∫—É—Å–≤–∏–ª–ª, –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å, –º–æ–≥—É –ª–∏ —è –ø—Ä–æ–≤–µ—Ä—è—Ç—å –º—è—Å–æ –Ω–∞ —Å–≤–µ–∂–µ—Å—Ç—å –ø—Ä–∏ –∫—É—Ä—å–µ—Ä–µ –¥–æ –æ–ø–ª–∞—Ç—ã? \\n–†–µ–¥–∫–æ —Å–µ–π—á–∞—Å —É –≤–∞—Å –∑–∞–∫–∞–∑—ã–≤–∞–µ–º, –¥–æ—Å—Ç–∞–≤–∫–∞ –¥–æ–ª–≥–∞—è, —è–∏—Ü–∞, –º—è—Å–æ –∏ –º–æ–ª–æ—á–∫–∞ –≤–æ–æ–±—â–µ –Ω–µ –æ—á–µ–Ω—å.\\n–í—Å–µ –ø–æ–Ω–∏–º–∞—é, –Ω–æ –∫–∞–∫ –µ—Å—Ç—å': {'first_name': '–í—Å—ë –¢–∞–∫–æ–µ',\n",
       "  'negative': 100.0,\n",
       "  'neutral': 0.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.014069014913155807},\n",
       " '100 —Ä–∞–∑ –∫—Ä—É—Ç–∏–ª–∞ –∫—Ä—ã—à–∫—É —Ç—É–¥–∞ —Å—é–¥–∞, –º–∞–º–∞ –∫—Ä—É—Ç–∏–ª–∞, –º—É–∂ –∫—Ä—É—Ç–∏–ª, –Ω–∏–∫–∞–∫ –Ω–µ –Ω–∞–∂–∏–º–∞–µ—Ç—Å—è –≤–æ–æ–±—â–µ –¥–æ–∑–∞—Ç–æ—Ä. –•–æ—á—É –≤–µ—Ä–Ω—É—Ç—å, —á—Ç–æ –¥–µ–ª–∞—Ç—å': {'first_name': '–ê–Ω–∞—Å—Ç–∞—Å–∏—è –ë–µ–ª–∫–∏–Ω–∞',\n",
       "  'negative': 75.0,\n",
       "  'neutral': 25.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.02558002711482874},\n",
       " '–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –†–µ—à–∏–ª–∞ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é —Å–º–µ—Ç–∞–Ω—É —Å —Ç–æ–º–∞—Ç–∞–º–∏ –∏ —Å–ø–µ—Ü–∏—è–º–∏ –∏ –≤—Å–µ –±—ã–ª–æ –±—ã —Ö–æ—Ä–æ—à–æ, –µ—Å–ª–∏ –±—ã –µ–µ –º–æ–∂–Ω–æ –±—ã–ª–æ –ª–µ–≥–∫–æ –∏ –ø—Ä–æ—Å—Ç–æ –æ—Ç–∫—Ä—ã—Ç—å. –ö—Ä–∞—Å–∏–≤–æ, –∫–æ–Ω–µ—á–Ω–æ, —Å–ø–æ—Ä—É –Ω–µ—Ç, –Ω–æ —Ñ–æ–ª—å–≥–∞ –Ω–∞–º–µ—Ä—Ç–≤–æ –ø—Ä–∏–∫–ª–µ–µ–Ω–∞ –∫ –∫—Ä–∞—è–º –±–∞–Ω–æ—á–∫–∏, –ø—Ä–∏—à–ª–æ—Å—å –≤—Å–∫—Ä—ã–≤–∞—Ç—å –Ω–æ–∂–æ–º, –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫—Ä—ã—à–∫–∏ —Ç–∞–∫–∂–µ –Ω–µ—É–¥–æ–±–Ω–æ. –ö—Ç–æ-—Ç–æ, –∫–æ–Ω–µ—á–Ω–æ, —É–ø–æ—Ç—Ä–µ–±–∏—Ç –≤–µ—Å—å –ø—Ä–æ–¥—É–∫—Ç —Å—Ä–∞–∑—É, –Ω–æ –∏–Ω–æ–≥–¥–∞ —Ç–∞–∫ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è. –•–æ—á–µ—Ç—Å—è, —á—Ç–æ–±—ã –≤—Å–µ –±—ã–ª–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ- –∏ –≤–∫—É—Å, –∏ —Ü–µ–Ω–∞, –∏ —É–¥–æ–±–Ω–∞—è —ç–∫–æ–ª–æ–≥–∏—á–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞': {'first_name': '–ù–∞—Ç–∞–ª—å—è –°–æ—Ä–æ–∫–∏–Ω–∞',\n",
       "  'negative': 60.0,\n",
       "  'neutral': 20.0,\n",
       "  'positive': 20.0,\n",
       "  'engagement_rate': 0.0345330366050188},\n",
       " '–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä! –Ø–≤–ª—è–µ–º—Å—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º–∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª—è–º–∏ –≤–∞—à–µ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞. –û—á–µ–Ω—å –ª—é–±–∏–ª–∏ –∏ –º–Ω–æ–≥–æ –ø–æ–∫—É–ø–∞–ª–∏ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤–∞—Ñ–ª–∏ \"–°–ª–∏–≤–æ—á–Ω—ã–µ\". –ù–µ–¥–∞–≤–Ω–æ –ø—Ä–∏—à–ª–∏ –≤ —É–∂–∞—Å –æ—Ç —É–≤–∏–¥–µ–Ω–Ω–æ–≥–æ. –í –≤–∞—Ñ–ª—è—Ö —á—ë—Ä–Ω—ã–µ –º–∞–ª–µ–Ω—å–∫–∏–µ —á–∞—Å—Ç–∏—á–∫–∏, –ø—Ä–∏—á—ë–º –æ–Ω–∏ –∂—ë—Å—Ç–∫–∏–µ, –∫–∞–∫ –ø–µ—Å–æ–∫. –ö–∞–∫ –≤—ã —ç—Ç–æ –æ–±—ä—è—Å–Ω–∏—Ç–µ? –ß—Ç–æ –≤—ã –ø—Ä–æ–¥–∞—ë—Ç–µ –¥–ª—è –ª—é–¥–µ–π? –ú—ã —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω—ã. –î–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –¥–∞–∂–µ –≤—ã–ª–æ–∂–∏–ª–∏ –∏—Ö –Ω–∞ —Å–∞–ª—Ñ–µ—Ç–∫—É, —á—Ç–æ–±—ã –±—ã–ª–æ –ª—É—á—à–µ –≤–∏–¥–Ω–æ. –ü—Ä–∏—á—ë–º —ç—Ç–æ –º–∞–ª–µ–Ω—å–∫–∏–µ –∫–∞–º–µ—à–∫–∏, –æ–Ω–∏ –Ω–µ —Ä–∞—Å—Å—Ç–≤–æ—Ä—è—é—Ç—Å—è –∏ –Ω–µ —Ä–∞–∑–º–∏–Ω–∞—é—Ç—Å—è.': {'first_name': 'Diana Khramova',\n",
       "  'negative': 50.0,\n",
       "  'neutral': 50.0,\n",
       "  'positive': 0.0,\n",
       "  'engagement_rate': 0.020464021691862993}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "class InfluencerTableNegative:\n",
    "    '''\n",
    "    –¢–æ–ø-10 –ø–æ—Å—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º —É—Ä–æ–≤–Ω–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ä–µ–∞–∫—Ü–∏–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏\n",
    "    [–ø–æ—Å—Ç | –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä | –Ω–µ–≥–∞—Ç–∏–≤ | –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ | –ø–æ–∑–∏—Ç–∏–≤ | –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å]\n",
    "    '''\n",
    "    def __init__(self, data, top_neg_posts=10):\n",
    "        self.data = data\n",
    "        self.top_neg_posts = top_neg_posts\n",
    "        self.__analyze_comments()\n",
    "        self.__engagement_rate_by_reach()\n",
    "\n",
    "    def __get_data(self):\n",
    "        dt = {}  \n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] is not None:\n",
    "                post_id = post['id']\n",
    "                if post_id not in dt:\n",
    "                    dt[post_id] = {\n",
    "                        'first_name': post['from']['first_name'],\n",
    "                        'last_name': post['from']['last_name'],\n",
    "                        'likes': post['reactions'][0]['count'],\n",
    "                        'messages': 1,\n",
    "                        'comments': [reply['text'] for reply in post['replies']],\n",
    "                        'reposts': post['forwards'],\n",
    "                        'followers': self.data['vk'][0]['membersCount'],\n",
    "                        'post': post['text']\n",
    "                    }\n",
    "                    \n",
    "        return dt\n",
    "\n",
    "    def __analyze_comments(self):\n",
    "        self.data = self.__get_data()\n",
    "        \n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "        \n",
    "        for id, info in self.data.items():\n",
    "            pos_count = 0\n",
    "            neg_count = 0\n",
    "            neu_count = 0\n",
    "            total_count = 0\n",
    "            \n",
    "            for comment in info['comments']:\n",
    "                result = classifier(comment)\n",
    "                sentiment = result[0]['label']\n",
    "                \n",
    "                if sentiment == 'NEGATIVE':\n",
    "                    neg_count += 1\n",
    "                elif sentiment == 'POSITIVE':\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neu_count += 1\n",
    "                \n",
    "                total_count += 1\n",
    "\n",
    "            pos_perc = (pos_count / total_count) * 100\n",
    "            neg_perc = (neg_count / total_count) * 100\n",
    "            neu_perc = (neu_count / total_count) * 100\n",
    "\n",
    "            info['positive_percentage'] = pos_perc\n",
    "            info['negative_percentage'] = neg_perc\n",
    "            info['neutral_percentage'] = neu_perc\n",
    "\n",
    "        sorted_data = sorted(self.data.items(), key=lambda x: x[1]['negative_percentage'], reverse=True)\n",
    "        self.neg_posts = sorted_data[:self.top_neg_posts]\n",
    "    \n",
    "    def __engagement_rate_by_reach(self):\n",
    "        '''\n",
    "        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ (Engagement Rate By Reach)\n",
    "        (–û–±—â–µ–µ —á–∏—Å–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π / –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞) * 100%\n",
    "        '''\n",
    "        for id, info in self.neg_posts:\n",
    "            total_interactions = info['likes'] + len(info['comments']) + info['reposts']\n",
    "            engagement_rate = (total_interactions / info['followers']) * 100\n",
    "            info['engagement_rate'] = engagement_rate\n",
    "    \n",
    "    def get_results_dict(self):\n",
    "        \n",
    "        results_dict = {}\n",
    "        \n",
    "        for id, info in self.neg_posts:\n",
    "            results_dict[info['post']] = {\n",
    "                'first_name': info['first_name'] + ' ' + info['last_name'],\n",
    "                'negative': info['negative_percentage'],\n",
    "                'neutral': info['neutral_percentage'],\n",
    "                'positive': info['positive_percentage'],\n",
    "                'engagement_rate': info['engagement_rate']\n",
    "            }\n",
    "        \n",
    "        # # {'–î—Ä—É–∑—å—è, –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã...',  {'first_name': '–ù–∞—Ç–∞–ª–∏—è –ú–∏–ª–∞–Ω–æ', 'negative': 100.0,  \n",
    "        # 'neutral': 0.0,  'positive': 0.0,  'engagement_rate': 0.01790601898038012}, '–í–æ—Ç —Ç–∞–∫–∏–µ —Å—Ç—Ä–∏–ø—Å—ã, –æ–¥–Ω–∏ –æ–±—Ä–µ–∑–∫–∏': {'first...   \n",
    "        return results_dict \n",
    "    \n",
    "    \n",
    "table = InfluencerTableNegative(data)\n",
    "table.get_results_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å —Ä–∞—Å—á–µ—Ç–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ –≤–µ–±-–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∫–æ–º–ø–∞–Ω–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/nermakovaa/semester_4/SNA/SNA/data/new_data.txt', 'r') as file:\n",
    "    file_content = file.read()\n",
    "    data = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: 0.9428571428571428\n",
      "–î–æ–ª—è –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: 0.1364914759727622\n",
      "–î–æ–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –∏–∑ —Ç–æ–ø–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: 1.0\n",
      "–°—Ä–µ–¥–Ω–∏–π Love rate –¥–ª—è –ø–æ—Å—Ç–æ–≤: 0.29066381564192006\n",
      "–î–æ–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–∑ —Ç–æ–ø–∞ –Ω–∞–∏–±–æ–ª–µ–µ –æ–±—Å—É–∂–¥–∞–µ–º—ã—Ö –ø–æ—Å—Ç–æ–≤: 0.8747222222222222\n",
      "–õ–æ—è–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –±—Ä–µ–Ω–¥–∞: 0.7304546087440823\n",
      "–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: 1.0\n",
      "–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –±—Ä–µ–Ω–¥–∞ –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: 1.0\n",
      "–û—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç—å –±—Ä–µ–Ω–¥–∞: 0.8947368421052632\n",
      "–î–æ–ª—è –ª–æ—è–ª—å–Ω—ã—Ö –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤: 0.7721836788283892\n",
      "–ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏: 0.01351995857259055\n",
      "–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–π—Ç–∏–Ω–≥: (69.59663404494884, '–ú–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è –±—Ä–µ–Ω–¥–∞')\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from transformers import pipeline\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def brand_follower_ratio(self):\n",
    "        '''\n",
    "        –î–æ–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "        '''\n",
    "        active_users = 0\n",
    "        followers = 0\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] != None:\n",
    "                active_users += 1\n",
    "                followers += post['from']['is_member']\n",
    "                \n",
    "        if active_users != 0:\n",
    "            return followers / active_users\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def user_engagement_ratio(self):\n",
    "        '''\n",
    "        –î–æ–ª—è –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "        '''\n",
    "        post_data = defaultdict(int)\n",
    "        post_count = len(self.data['vk'][0]['posts'])\n",
    "\n",
    "        ratios = []\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            sender_ids = set(comment['sender_id'] for comment in post['replies'])\n",
    "\n",
    "            unique_sender_count = len(sender_ids)\n",
    "            unique_forward_count = post['forwards']\n",
    "            unique_reaction_count = post['reactions'][0]['count']\n",
    "\n",
    "            post_data[post['id']] = {\n",
    "                'unique_sender_count': unique_sender_count,\n",
    "                'unique_forward_count': unique_forward_count,\n",
    "                'unique_reaction_count': unique_reaction_count\n",
    "            }\n",
    "\n",
    "            ratios.append(unique_sender_count / (unique_sender_count + unique_forward_count + unique_reaction_count))\n",
    "\n",
    "        if post_count != 0:\n",
    "            return sum(ratios) / post_count\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def top_audience_ratio(self):\n",
    "        '''\n",
    "        –î–æ–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –∏–∑ —Ç–æ–ø–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "        '''\n",
    "        active_users = 0\n",
    "        followers = 0\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] != None:\n",
    "                sorted_posts = sorted(self.data['vk'][0]['posts'], key=lambda x: (x['views'] if x['views'] is not None else len(x['replies'])) if x['from'] is not None else -1, reverse=True)\n",
    "                top_posts = sorted_posts[:10]\n",
    "\n",
    "        for post in top_posts:\n",
    "            active_users += 1\n",
    "            followers += post['from']['is_member']\n",
    "                \n",
    "        if active_users != 0:\n",
    "            return followers / active_users\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def love_rate(self):\n",
    "        '''\n",
    "        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "        '''\n",
    "        love_rate_sum = 0\n",
    "        post_count = 0\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['views'] is not None:\n",
    "                views = post['views']\n",
    "                likes = post['reactions'][0]['count']\n",
    "                \n",
    "                love_rate = likes / views\n",
    "                \n",
    "                love_rate_sum += love_rate\n",
    "                post_count += 1\n",
    "\n",
    "        if post_count != 0:\n",
    "            return (love_rate_sum / post_count) / 0.05\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    def trending_content_sentiment_ratio(self):\n",
    "        '''\n",
    "        –î–æ–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–∑ —Ç–æ–ø–∞ –Ω–∞–∏–±–æ–ª–µ–µ –æ–±—Å—É–∂–¥–∞–µ–º—ã—Ö –ø–æ—Å—Ç–æ–≤\n",
    "        '''\n",
    "        posts_with_replies = []\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            post_id = post['id']\n",
    "            replies = post['replies']\n",
    "            \n",
    "            if replies:\n",
    "                posts_with_replies.append({'post_id': post_id, 'replies_count': len(replies), 'replies': replies})\n",
    "                \n",
    "        sorted_posts = sorted(posts_with_replies, key=lambda x: x['replies_count'], reverse=True)\n",
    "        top_posts = sorted_posts[:10]\n",
    "        \n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "        post_sentiments = {}\n",
    "\n",
    "        for post in top_posts:\n",
    "            post_id = post['post_id']\n",
    "            replies = post['replies']\n",
    "            \n",
    "            positive_count = 0\n",
    "            negative_count = 0\n",
    "            \n",
    "            for reply in replies:\n",
    "                text = reply['text']\n",
    "                tone = classifier(text)[0]['label']\n",
    "                \n",
    "                if tone == 'POSITIVE':\n",
    "                    positive_count += 1\n",
    "                elif tone == 'NEGATIVE':\n",
    "                    negative_count += 1\n",
    "            \n",
    "            post_sentiments[post_id] = {'positive_count': positive_count, 'negative_count': negative_count}\n",
    "\n",
    "        total_loyalty = 0\n",
    "        \n",
    "        for post_id, counts in post_sentiments.items():\n",
    "            total_comments = counts['positive_count'] + counts['negative_count']\n",
    "            positive_ratio = counts['positive_count'] / total_comments if total_comments != 0 else 0\n",
    "\n",
    "            total_loyalty += positive_ratio\n",
    "\n",
    "        if len(post_sentiments) != 0:\n",
    "            return total_loyalty / len(post_sentiments)\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    def net_promoter_score(self):\n",
    "        '''\n",
    "        –õ–æ—è–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –±—Ä–µ–Ω–¥–∞\n",
    "        '''\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "        post_sentiments = {}\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if len(post['replies']) != 0:\n",
    "                post_id = post['id']\n",
    "                replies = post['replies']\n",
    "                \n",
    "                positive_count = 0\n",
    "                negative_count = 0\n",
    "                \n",
    "                for reply in replies:\n",
    "                    text = reply['text']\n",
    "                    tone = classifier(text)[0]['label'] \n",
    "                    \n",
    "                    if tone == 'POSITIVE':\n",
    "                        positive_count += 1\n",
    "                    elif tone == 'NEGATIVE':\n",
    "                        negative_count += 1\n",
    "                \n",
    "                post_sentiments[post_id] = {'positive_count': positive_count, 'negative_count': negative_count}\n",
    "\n",
    "        total_loyalty = 0\n",
    "\n",
    "        for post_id, counts in post_sentiments.items():\n",
    "            total_comments = counts['positive_count'] + counts['negative_count']\n",
    "            positive_ratio = counts['positive_count'] / total_comments if total_comments != 0 else 0\n",
    "\n",
    "            total_loyalty += positive_ratio\n",
    "\n",
    "        if len(post_sentiments) != 0:\n",
    "            return total_loyalty / len(post_sentiments)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def brand_response_to_comments(self):\n",
    "        '''\n",
    "        –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏\n",
    "        '''\n",
    "        count_1 = 0\n",
    "        count_0 = 0\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            text = post['text'].lower()\n",
    "            brand_name = self.data['vk'][0]['groupName'].lower()\n",
    "            \n",
    "            if brand_name in text:\n",
    "                for reply in post['replies']:\n",
    "                    if reply.get('sender_name', '').lower() in brand_name or reply.get('last_name', '').lower() in brand_name:\n",
    "                        count_1 += 1\n",
    "                        break\n",
    "                else:\n",
    "                    count_0 += 1\n",
    "\n",
    "        total_posts = count_1 + count_0\n",
    "\n",
    "        if total_posts != 0:\n",
    "            return (count_1 + count_0) / total_posts\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def brand_reaction_to_negativity(self):\n",
    "        count_1 = 0\n",
    "        count_0 = 0\n",
    "\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            text = post['text'].lower()\n",
    "            brand_name = self.data['vk'][0]['groupName'].lower()\n",
    "            \n",
    "            if brand_name in text:\n",
    "                result = classifier(text)\n",
    "                tone = result[0]['label']\n",
    "\n",
    "                if tone == 'NEGATIVE':\n",
    "                    for reply in post['replies']:\n",
    "                        if reply.get('sender_name', '').lower() in brand_name or reply.get('last_name', '').lower() in brand_name:\n",
    "                            count_1 += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        count_0 += 1\n",
    "\n",
    "        total_posts = count_1 + count_0\n",
    "\n",
    "        if total_posts != 0:\n",
    "            return (count_1 + count_0) / total_posts\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def brand_responsiveness(self):\n",
    "        '''\n",
    "        –û—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç—å –±—Ä–µ–Ω–¥–∞\n",
    "        '''\n",
    "        answers = 0\n",
    "        posts = 0\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            posts += 1\n",
    "            post_answered = False  \n",
    "            for replies in post['replies']:\n",
    "                if (replies['sender_name'].lower() in self.data['vk'][0]['groupName'].lower()) == True or (replies['last_name'].lower() in self.data['vk'][0]['groupName'].lower()) == True:\n",
    "                    answers += 1\n",
    "                    post_answered = True \n",
    "                    break  \n",
    "            if post_answered:  \n",
    "                continue\n",
    "\n",
    "        if posts != 0:\n",
    "            return answers / posts\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def influencer_sentiment_ratio(self):\n",
    "        '''\n",
    "        –î–æ–ª—è –ª–æ—è–ª—å–Ω—ã—Ö –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤ –∏–∑ —Ç–æ–ø–∞\n",
    "        '''\n",
    "        connections = []\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] != None:\n",
    "                post_connections = [(post['from']['id'], reply['sender_id']) for reply in post['replies']]\n",
    "                connections.extend(post_connections)\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(connections)\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=20) \n",
    "\n",
    "        # pagerank - https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
    "        pr = nx.pagerank(G)\n",
    "        sorted_pr = sorted(pr.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        top_10_pr = sorted_pr[:10] \n",
    "        top_10_ids_pr = [id for id, pr in top_10_pr]\n",
    "\n",
    "        # https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html\n",
    "        centrality = nx.betweenness_centrality(G)\n",
    "        sorted_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        top_10_centrality = sorted_centrality[:10] \n",
    "        top_10_ids_centrality = [id for id, _ in top_10_centrality]\n",
    "\n",
    "        top_users = list(set(top_10_ids_pr + top_10_ids_centrality))\n",
    "\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=\"blanchefort/rubert-base-cased-sentiment\")\n",
    "\n",
    "        user_sentiments = {}\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['from'] is not None and post['from']['id'] in top_users:\n",
    "                text = post['text']\n",
    "                result = classifier(text)[0]\n",
    "\n",
    "                user_id = post['from']['id']\n",
    "                if user_id not in user_sentiments:\n",
    "                    user_sentiments[user_id] = {\"POSITIVE\": 0, \"NEGATIVE\": 0}\n",
    "\n",
    "                if result['label'] == 'POSITIVE':\n",
    "                    user_sentiments[user_id][\"POSITIVE\"] += 1\n",
    "                elif result['label'] == 'NEGATIVE':\n",
    "                    user_sentiments[user_id][\"NEGATIVE\"] += 1\n",
    "\n",
    "            for reply in post['replies']:\n",
    "                if reply['sender_id'] in top_users:\n",
    "                    text = reply['text']\n",
    "                    result = classifier(text)[0]\n",
    "\n",
    "                    user_id = reply['sender_id']\n",
    "                    if user_id not in user_sentiments:\n",
    "                        user_sentiments[user_id] = {\"POSITIVE\": 0, \"NEGATIVE\": 0}\n",
    "\n",
    "                    if result['label'] == 'POSITIVE':\n",
    "                        user_sentiments[user_id][\"POSITIVE\"] += 1\n",
    "                    elif result['label'] == 'NEGATIVE':\n",
    "                        user_sentiments[user_id][\"NEGATIVE\"] += 1\n",
    "\n",
    "        loyalty_scores = {}\n",
    "\n",
    "        for user_id, sentiment_info in user_sentiments.items():\n",
    "            positive = sentiment_info['POSITIVE']\n",
    "            negative = sentiment_info['NEGATIVE']\n",
    "\n",
    "            loyalty_score = positive / (positive + negative) if (positive + negative) > 0 else 0\n",
    "            loyalty_scores[user_id] = loyalty_score\n",
    "\n",
    "        if len(loyalty_scores.values()) != 0:\n",
    "            return sum(loyalty_scores.values()) / len(loyalty_scores.values())\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    def channel_citation_index(self):\n",
    "        '''\n",
    "        –ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏\n",
    "        '''\n",
    "        channel_citation_sum = 0\n",
    "        post_count = 0\n",
    "\n",
    "        for post in self.data['vk'][0]['posts']:\n",
    "            if post['views'] is not None:\n",
    "                views = post['views']\n",
    "                forwards = post['forwards']\n",
    "                \n",
    "                channel_citation_index = forwards / views\n",
    "                \n",
    "                channel_citation_sum += channel_citation_index\n",
    "                post_count += 1\n",
    "\n",
    "        if post_count != 0:\n",
    "            return (channel_citation_sum / post_count) / 0.05\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def calculate_model(self, weight=tuple((100 / 11) for _ in range(11))):\n",
    "        '''\n",
    "        –ò—Ç–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "        weight - –∫–æ—Ä—Ç–µ–∂ –∏–∑ –≤–µ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞–≤–Ω–æ–∑–Ω–∞—á–Ω—ã)\n",
    "        '''\n",
    "        name_groups = ['–ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏', '–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –∞—É–¥–∏—Ç–æ—Ä–∏–∏',\n",
    "            '–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–π –±—Ä–µ–Ω–¥–∞', '–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∏–≤–∞–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–∞–º–∏',\n",
    "            '–ú–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è –±—Ä–µ–Ω–¥–∞']\n",
    "        \n",
    "        indicators = (self.brand_follower_ratio(), self.user_engagement_ratio(), self.top_audience_ratio(), self.love_rate(),\n",
    "                    self.trending_content_sentiment_ratio(), self.net_promoter_score(), self.brand_response_to_comments(), \n",
    "                    self.brand_reaction_to_negativity(), self.brand_responsiveness(), self.influencer_sentiment_ratio(), self.channel_citation_index())\n",
    "        \n",
    "        # –ø—Ä–∏ –ø–æ–¥—Å—á–µ—Ç–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –≤–µ—Å–∞ –ø–æ–ª—É—á–∞–µ–º –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞\n",
    "        result = [w * v for w, v in zip(weight, indicators)] \n",
    "        result_model = sum(result)\n",
    "        \n",
    "        # –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö –≤–µ—Å–∞ –Ω–µ –º–µ–Ω—è–µ–º\n",
    "        result_min = [w * v for w, v in zip(tuple((100 / 11) for _ in range(11)), indicators)] \n",
    "        group = [sum(result_min[:3])/3, sum(result_min[3:6])/3, sum(result_min[6:9])/3, result_min[9], result_min[10]]\n",
    "        min_group = group.index(min(group))\n",
    "        \n",
    "        return result_model, name_groups[min_group] # result_model - –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–π—Ç–∏–Ω–≥, (name_groups[min_group]) - –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–ª–∞–±–æ–π –≥—Ä—É–ø–ø—ã \n",
    "\n",
    "\n",
    "user = Model(data)\n",
    "print(f\"–î–æ–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {user.brand_follower_ratio()}\") \n",
    "print(f\"–î–æ–ª—è –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—â–∏—Ö —Å—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {user.user_engagement_ratio()}\")\n",
    "print(f\"–î–æ–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤ –∏–∑ —Ç–æ–ø–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {user.top_audience_ratio()}\") \n",
    "print(f\"–°—Ä–µ–¥–Ω–∏–π Love rate –¥–ª—è –ø–æ—Å—Ç–æ–≤: {user.love_rate()}\")\n",
    "print(f\"–î–æ–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏–∑ —Ç–æ–ø–∞ –Ω–∞–∏–±–æ–ª–µ–µ –æ–±—Å—É–∂–¥–∞–µ–º—ã—Ö –ø–æ—Å—Ç–æ–≤: {user.trending_content_sentiment_ratio()}\")\n",
    "print(f\"–õ–æ—è–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –±—Ä–µ–Ω–¥–∞: {user.net_promoter_score()}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: {user.brand_response_to_comments()}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –±—Ä–µ–Ω–¥–∞ –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏: {user.brand_reaction_to_negativity()}\") \n",
    "print(f\"–û—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç—å –±—Ä–µ–Ω–¥–∞: {user.brand_responsiveness()}\")\n",
    "print(f\"–î–æ–ª—è –ª–æ—è–ª—å–Ω—ã—Ö –∏–Ω—Ñ–ª—é–µ–Ω—Å–µ—Ä–æ–≤: {user.influencer_sentiment_ratio()}\") \n",
    "print(f\"–ò–Ω–¥–µ–∫—Å —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç–∏: {user.channel_citation_index()}\")\n",
    "\n",
    "print(f\"–ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–π—Ç–∏–Ω–≥: {user.calculate_model()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
